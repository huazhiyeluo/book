{"./":{"url":"./","title":"前言","keywords":"","body":"空着，没想好写什么…… [!NOTE] 这是一个简单的Note类型的使用，所有的属性都是默认值。 emoji [!TIP] 这是一个简单的Note类型的使用，所有的属性都是默认值。 emoji [!WARNING] An alert of type 'comment' using style 'callout' with default settings. emoji [!DANGER] An alert of type 'comment' using style 'callout' with default settings. %accordion%知识点 %accordion% Any content here %/accordion% 点击显示 要被隐藏的内容 [success] INFO Use this for success messages. This text is highlighted in red! "},"db/db.html":{"url":"db/db.html","title":"1. 数据库篇","keywords":"","body":"1. memcached 安装 配置说明 命令 2. redis 安装 配置说明 命令 3. mongodb 安装 配置说明 命令 4. sqlite3 安装 配置说明 命令 5. mysql 安装 配置说明 命令 "},"db/memcached.html":{"url":"db/memcached.html","title":"1.1 memcached","keywords":"","body":"1. 安装 wget http://memcached.org/latest 下载最新版本tar -zxvf memcached-1.x.x.tar.gz 解压源码cd memcached-1.x.x 进入目录./configure --prefix=/usr/local/memcached 配置make && make test 编译sudo make install 安装 2. 配置说明 启动方式： /usr/local/bin/memcached -d -m 1024 -u root -l 127.0.0.1 -p 11211 -c 1024 -P /tmp/memcached.pid -d 是启动一个守护进程； -m 是分配给Memcache使用的内存数量，单位是MB； -u 是运行Memcache的用户； -l 是监听的服务器IP地址，可以有多个地址； -p 是设置Memcache监听的端口，，最好是1024以上的端口； -c 是最大运行的并发连接数，默认是1024； -P 是设置保存Memcache的pid文件。访问方式：telnet IP PORT 3. 命令 1.设置命令 1、set：如果set的key已经存在，该命令可以更新该key所对应的原来的数据，也就是实现更新的作用。 set key flags exptime bytes [noreply] value 2、add：如果 add 的 key 已经存在，则不会更新数据(过期的 key 会更新)，之前的值将仍然保持相同，并且您将获得响应 NOT_STORED。 add key flags exptime bytes [noreply] value 3、replace：如果 key 不存在，则替换失败，并且您将获得响应 NOT_STORED。 replace key flags exptime bytes [noreply] value 4、append：Memcached append 命令用于向已存在 key(键) 的 value(数据值) 后面追加数据 。 append key flags exptime bytes [noreply] value 5、prepend：Memcached prepend 命令用于向已存在 key(键) 的 value(数据值) 前面追加数据 。 prepend key flags exptime bytes [noreply] value 6、cas：Memcached CAS（Check-And-Set 或 Compare-And-Swap） 命令用于执行一个\"检查并设置\"的操作.它仅在当前客户端最后一次取值后，该key 对应的值没有被其他客户端修改的情况下， 才能够将值写入。检查是通过cas_token参数进行的， 这个参数是Memcach指定给已经存在的元素的一个唯一的64位值。 cas key flags exptime bytes unique_cas_token [noreply] value cas tp 0 900 9 ERROR #缺少 token cas tp 0 900 9 2 memcached NOT_FOUND #键 tp 不存在 set tp 0 900 9 memcached STORED gets tp VALUE tp 0 9 1 memcached END cas tp 0 900 5 1 redis STORED get tp VALUE tp 0 5 redis END 参数说明如下： key：键值 key-value 结构中的 key，用于查找缓存值。 flags：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 。 exptime：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes：在缓存中存储的字节数 unique_cas_token通过 gets 命令获取的一个唯一的64位值。 noreply（可选）： 该参数告知服务器不需要返回数据 value：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 2.查找命令 1、get：Memcached get 命令获取存储在 key(键) 中的 value(数据值) ，如果 key 不存在，则返回空。 get key get key1 key2 key3 2、gets：Memcached gets 命令获取带有 CAS 令牌存 的 value(数据值) ，如果 key 不存在，则返回空。 gets key gets key1 key2 key3 3、delete：Memcached delete 命令用于删除已存在的 key(键)。 delete key [noreply] 4、incr/decr：Memcached incr 与 decr 命令用于对已存在的 key(键) 的数字值进行自增或自减操作。incr 与 decr 命令操作的数据必须是十进制的32位无符号整数。如果 key 不存在返回 NOT_FOUND，如果键的值不为数字，则返回 CLIENT_ERROR，其他错误返回 ERROR。 incr key increment_value value 3.统计命令 1、stats：Memcached stats 命令用于返回统计信息例如 PID(进程号)、版本号、连接数等。 stats 2、stats items：Memcached stats items 命令用于显示各个 slab 中 item 的数目和存储时长(最后一次访问距离现在的秒数)。 stats items 3、stats slabs：Memcached stats slabs 命令用于显示各个slab的信息，包括chunk的大小、数目、使用情况等。 stats slabs 4、stats sizes：Memcached stats sizes 命令用于显示所有item的大小和个数。该信息返回两列，第一列是 item 的大小，第二列是 item 的个数。 stats sizes 5、flush_all：Memcached flush_all 命令用于清理缓存中的所有 key=>value(键=>值) 对。该命令提供了一个可选参数 time，用于在制定的时间后执行清理缓存操作。 flush_all [time] [noreply] 6、stats detail [on|off|dump]：设置或者显示详细操作记录 stats detail [on|off|dump] 7、stats cachedump slab_id limit_num：显示某个slab中的前limit_num个key列表. stats cachedump 7 2 8、stats reset：清空统计数据 stats reset 4.其他信息 1、统计信息（stats） 参数 值 描述 pid 1700 memcache服务器进程ID uptime 5335604 服务器已运行秒数 time 1557036895 服务器当前Unix时间戳 version 1.5.10 memcache版本 libevent 2.0.21-stable libevent版本 pointer_size 64 操作系统指针大小 rusage_user 805.137191 进程累计用户时间 rusage_system 460.201782 进程累计系统时间 max_connections 256 curr_connections 3 当前连接数量 total_connections 7742 Memcached运行以来连接总数 rejected_connections 0 connection_structures 5 Memcached分配的连接结构数量 reserved_fds 20 内部使用的FD数 cmd_get 6977 get命令请求次数 cmd_set 193 set命令请求次数 cmd_flush 0 flush命令请求次数 cmd_touch 0 touch命令请求次数 get_hits 6767 get命令命中次数 get_misses 210 get命令未命中次数 get_expired 1 get_flushed 0 delete_misses 4 delete命令未命中次数 delete_hits 4 delete命令命中次数 incr_misses 0 incr命令未命中次数 incr_hits 0 incr命令命中次数 decr_misses 0 decr命令未命中次数 decr_hits 0 decr命令命中次数 cas_misses 0 cas命令未命中次数 cas_hits 0 cas命令命中次数 cas_badval 0 使用擦拭次数 touch_hits 0 touch命令命中次数 touch_misses 0 touch命令未命中次数 auth_cmds 0 认证命令处理的次数 auth_errors 0 认证失败数目 bytes_read 9227571 读取总字节数 bytes_written 63626954 发送总字节数 limit_maxbytes 67108864 分配的内存总大小（字节） accepting_conns 1 接受新的连接 listen_disabled_num 0 失效的监听数 time_in_listen_disabled_us 0 threads 4 当前线程数 conn_yields 0 连接操作主动放弃数目 hash_power_level 16 hash表等级 hash_bytes 524288 当前hash表大小 hash_is_expanding 0 hash表正在扩展 slab_reassign_rescues 0 slab_reassign_chunk_rescues 0 slab_reassign_evictions_nomem 0 slab_reassign_inline_reclaim 0 slab_reassign_busy_items 0 slab_reassign_busy_deletes 0 slab_reassign_running 0 slabs_moved 0 lru_crawler_running 0 lru_crawler_starts 384795 lru_maintainer_juggles 32123450 malloc_fails 0 log_worker_dropped 0 log_worker_written 0 log_watcher_skipped 0 log_watcher_sent 0 bytes 1714945 当前存储占用的字节数 curr_items 6 当前存储的数据总数 total_items 193 启动以来存储的数据总数 slab_global_page_pool 0 expired_unfetched 9 已过期但未获取的对象数目 evicted_unfetched 0 已驱逐但未获取的对象数目 evicted_active 0 evictions 0 LRU释放的对象数目 reclaimed 171 已过期的数据条目来存储新数据的数目 crawler_reclaimed 1 crawler_items_checked 6406 lrutail_reflocked 3584 moves_to_cold 6295 moves_to_warm 6104 moves_within_lru 258 direct_reclaims 0 lru_bumps_dropped 0 2、区块信息（stats slabs） 参数 值 描述 active_slabs 10 slab数量 total_malloced 11534336 总内存数量 选择内存区块：SLAB : 1 参数 值 描述 chunk_size 96 chunk大小（byte） chunks_per_page 10922 每个page的chunk数量 total_pages 1 page数量 total_chunks 10922 chunk总数量（chunks_per_page*total_pages） used_chunks 0 已被分配的chunk数量 free_chunks 10922 过期数据空出的chunk数 free_chunks_end 0 从未被使用过的chunk数 mem_requested 0 请求存储的字节数 get_hits 2 get命令命中数 cmd_set 2 set命令请求数 delete_hits 0 delete命令命中数 incr_hits 0 incr命令命中数 decr_hits 0 decr命令命中数 cas_hits 0 cas命令命中数 cas_badval 0 cas数据类型错误数 touch_hits 0 touch命令命中数 3、ITEMS信息（stats items） 参数 值 描述 number 1 该slab中对象数（不包含过期对象） number_hot 0 number_warm 0 number_cold 1 age_hot 0 age_warm 0 age 284 LRU队列中最老对象的过期时间 evicted 0 LRU释放对象数 evicted_nonzero 0 设置了非0时间的LRU释放对象数 evicted_time 0 最后一次LRU释放的对象存在时间 outofmemory 0 不能存储对象次数 tailrepairs 0 修复slabs次数 reclaimed 35 使用过期对象空间存储对象次数 expired_unfetched 0 已过期但未获取的对象数目 evicted_unfetched 0 已驱逐但未获取的对象数目 evicted_active 0 crawler_reclaimed 0 crawler_items_checked 850 lrutail_reflocked 484 moves_to_cold 1004 moves_to_warm 968 moves_within_lru 15 direct_reclaims 0 hits_to_hot 1 hits_to_warm 19 hits_to_cold 1012 hits_to_temp 0 "},"db/redis.html":{"url":"db/redis.html","title":"1.2 redis","keywords":"","body":"1. 安装 wget http://download.redis.io/releases/redis-5.0.4.tar.gz 下载最新版本tar -zxvf redis-5.0.4.tar.gz 解压源码cd redis-5.0.4 进入目录make 配置 2. 配置说明 启动方式： ./redis-server ../redis.conf redis.conf 配置文件 daemonize no Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 pidfile /var/run/redis.pid 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 port 6379 指定Redis监听端口，默认端口为6379 bind 127.0.0.1 绑定的主机地址 timeout 300 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 loglevel verbose 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose logfile stdout 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null databases 16 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id save 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合， save 900 1，save 300 10，save 60 10000 ，分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 rdbcompression yes 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 dbfilename dump.rdb 指定本地数据库文件名，默认值为dump.rdb dir ./ 指定本地数据库存放目录 slaveof 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 masterauth 当master服务设置了密码保护时，slav服务连接master的密码 requirepass foobared 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭 maxclients 128 设置同一时间最大客户端连接数，默认无限制 maxmemory 指定Redis最大内存限制 appendonly no 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no appendfilename appendonly.aof 指定更新日志文件名，默认为appendonly.aof appendfsync everysec 指定更新日志条件，共有3个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快），always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） ，everysec：表示每秒同步一次（折中，默认值） vm-enabled no 指定是否启用虚拟内存机制，默认值为no， vm-swap-file /tmp/redis.swap 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-max-memory 0 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-page-size 32 Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 vm-pages 134217728 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 vm-max-threads 4 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 glueoutputbuf yes 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 hash-max-zipmap-entries 64、hash-max-zipmap-value 512 activerehashing yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 include /path/to/local.conf 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 访问方式：redis-cli -h 192.168.1.27 -p 6379关闭服务：redis-cli shutdown 3. 数据类型介绍 基本类型：字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets）范围查询类型： bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询 二进制安全的字符串 Lists: 按插入顺序排序的字符串元素的集合。他们基本上就是链表（linked lists）。 Sets: 不重复且无序的字符串元素的集合。 Sorted sets,类似Sets,但是每个字符串元素都关联到一个叫score浮动数值（floating number value）。里面的元素总是通过score进行着排序，所以不同的是，它是可以检索的一系列元素。（例如你可能会问：给我前面10个或者后面10个元素）。 Hashes,由field和关联的value组成的map。field和value都是字符串的。这和Ruby、Python的hashes很像。 Bit arrays (或者说 simply bitmaps): 通过特殊的命令，你可以将 String 值当作一系列 bits 处理：可以设置和清除单独的 bits，数出所有设为 1 的 bits 的数量，找到最前的被设为 1 或 0 的 bit，等等。 HyperLogLogs: 这是被用于估计一个 set 中元素数量的概率性的数据结构。 3. 命令 1.键（key） 1、del：如果set的key已经存在，该命令可以更新该key所对应的原来的数据，也就是实现更新的作用。 DEL key [key ...] 2、dump：序列化给定 key ，并返回被序列化的值，使用 RESTORE 命令可以将这个值反序列化为 Redis 键。 DUMP key 3、restore：反序列化给定的序列化值，并将它和给定的 key 关联。 RESTORE key ttl \"\\x00\\x04liao\\t\\x00\\xb4\\xa8\\xbb\\xf1\\x01C\\x1b\\xf6\" 4、exists：返回key是否存在。1 如果key存在,0 如果key不存在 EXISTS key [key ...] 5、keys：查找所有符合给定模式pattern（正则表达式）的 key 。 KEYS pattern 6、expire（pexpire 毫秒）：设置key的过期时间，超过时间后，将会自动删除该key。在Redis的术语中一个key的相关超时是不确定的。1 如果成功设置过期时间。0 如果key不存在或者不能设置过期时间。 EXPIRE key 10 7、expireat（pexpireat 毫秒）: 的作用和 EXPIRE类似，都用于为 key 设置生存时间。不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳 Unix timestamp 。 EXPIREAT key 1293840000 8、migrate: 将 key 原子性地从当前实例传送到目标实例的指定数据库上，一旦传送成功， key 保证会出现在目标实例上，而当前实例上的 key 会被删除。 migrate ip port key | destination-db timeout [copy] [replace] [keys key] 9、move: 将当前数据库的 key 移动到给定的数据库 db 当中。如果当前数据库(源数据库)和给定数据库(目标数据库)有相同名字的给定 key ，或者 key 不存在于当前数据库，那么 MOVE 没有任何效果。移动成功返回 1，失败则返回 0 move key db、move name 2 10、object: OBJECT 命令可以在内部调试(debugging)给出keys的内部对象，它用于检查或者了解你的keys是否用到了特殊编码 的数据类型来存储空间z。 当redis作为缓存使用的时候，你的应用也可能用到这些由OBJECT命令提供的信息来决定应用层的key的驱逐策略(eviction policies) OBJECT subcommand [arguments [arguments ...]] lpush mylist \"Hello World\" object refcount mylist object encoding mylist object idletime mylist OBJECT 命令可以在内部调试(debugging)给出keys的内部对象，它用于检查或者了解你的keys是否用到了特殊编码 的数据类型来存储空间z。 当redis作为缓存使用的时候，你的应用也可能用到这些由OBJECT命令提供的信息来决定应用层的key的驱逐策略(eviction policies) OBJECT ENCODING 该命令返回指定key对应value所使用的内部表示(representation)(译者注：也可以理解为数据的压缩方式). OBJECT IDLETIME 该命令返回指定key对应的value自被存储之后空闲的时间，以秒为单位(没有读写操作的请求) ，这个值返回以10秒为单位的秒级别时间，这一点可能在以后的实现中改善 11、persist: 移除给定key的生存时间，将这个 key 从『易失的』(带生存时间 key )转换成『持久的』(一个不带生存时间、永不过期的 key )。 SET mykey \"Hello\" EXPIRE mykey 10 TTL mykey PERSIST mykey TTL mykey 12、ttl（pttl 毫秒）: 返回key剩余的过期时间 TTL mykey 13、randomkey: 从当前数据库返回一个随机的key。 randomkey 14、rename: 将key重命名为newkey，如果key与newkey相同，将返回一个错误。如果newkey已经存在，则值将被覆盖。 RENAME mykey myotherkey 15、renamenx: 当且仅当 newkey 不存在时，将 key 改名为 newkey 。当 key 不存在时，返回一个错误。 RENAMENX mykey myotherkey 16、scan: 它们每次执行都只会返回少量元素，所以这些命令可以用于生产环境，而不会出现像 KEYS 或者 SMEMBERS 命令带来的可能会阻塞服务器的问题。 SCAN cursor [MATCH pattern] [COUNT count] 17、touch: 修改指定key(s) 最后访问时间 若key不存在，不做操作 TOUCH key [key ...] 18、unlink：该命令和DEL十分相似：删除指定的key(s),若key不存在则该key被跳过。但是，相比DEL会产生阻塞，该命令会在另一个线程中回收内存，因此它是非阻塞的。 这也是该命令名字的由来：仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。 UNLINK key [key ...] 2.字符串（string） 1、append：如果 key 已经存在，并且值为字符串，那么这个命令会把 value 追加到原来值（value）的结尾。 如果 key 不存在，那么它将首先创建一个空字符串的key，再执行追加操作，这种情况 APPEND 将类似于 SET 操作。返回append后字符串值（value）的长度。 APPEND key value 2、bitcount：统计字符串被设置为1的bit数. BITCOUNT key [start end] 3、decr/incr：对key对应的数字做减1操作。如果key不存在，那么在操作之前，这个key对应的值会被置为0。如果key有一个错误类型的value或者是一个不能表示成数字的字符串，就返回错误。这个操作最大支持在64位有符号的整型数字。 DECR key 4、decrby/incrby：将key对应的数字减decrement。如果key不存在，操作之前，key就会被置为0。如果key的value类型错误或者是个不能表示成数字的字符串，就返回错误。这个操作最多支持64位有符号的正型数字。 DECRBY mykey 5/DECRBY mykey 5 5、get：返回key的value。如果key不存在，返回特殊值nil。如果key的value不是string，就返回错误，因为GET只处理string类型的values。 GET mykey 6、getbit：返回key对应的string在offset处的bit值 当offset超出了字符串长度的时候，这个字符串就被假定为由0比特填充的连续空间. GETBIT mykey 100 7、getrange：这个命令是被改成GETRANGE的，在小于2.0的Redis版本中叫SUBSTR。 返回key对应的字符串value的子串，这个子串是由start和end位移决定的（两者都在string内）。可以用负的位移来表示从string尾部开始数的下标。所以-1就是最后一个字符，-2就是倒数第二个，以此类推。 GETRANGE key start end 8、getset：自动将key对应到value并且返回原来key对应的value。如果key存在但是对应的value不是字符串，就返回错误。返回之前的旧值，如果之前Key不存在将返回nil。 INCR mycounter GETSET mycounter \"0\" GET mycounter 9、mget：返回所有指定的key的value。对于每个不对应string或者不存在的key，都返回特殊值nil。正因为此，这个操作从来不会失败。 MGET key1 key2 nonexisting 10、mset：对应给定的keys到他们相应的values上。MSET会用新的value替换已经存在的value，就像普通的SET命令一样。如果你不想覆盖已经存在的values，请参看命令MSETNX。 MSET key1 \"Hello\" key2 \"World\" 11、msetnx：对应给定的keys到他们相应的values上。只要有一个key已经存在，MSETNX一个操作都不会执行。 由于这种特性，MSETNX可以实现要么所有的操作都成功，要么一个都不执行，这样可以用来设置不同的key，来表示一个唯一的对象的不同字段。 MSETNX key1 \"Hello\" key2 \"there\" 12、set：将键key设定为指定的“字符串”值。如果key已经保存了一个值，那么这个操作会直接覆盖原来的值，并且忽略原始类型。当set命令执行成功之后，之前设置的过期时间都将失效 SET key value [EX seconds] [PX milliseconds] [NX|XX] set phone xiaomi ex 50 13、setbit：设置或者清空key的value(字符串)在offset处的bit值。 SETBIT mykey 7 1 14、setex：设置key对应字符串value，并且设置key在给定的seconds时间之后超时过期。这个命令等效于执行下面的命令： SET mykey value EXPIRE mykey seconds SETEX mykey 10 \"Hello\" 3.列表（list） 1、blpop/brpop：当没有元素的时候会弹出一个 nil 的多批量值，并且 timeout 过期。当有元素弹出时会返回一个双元素的多批量值，其中第一个元素是弹出元素的 key，第二个元素是 value。 BLPOP key [key ...] timeout 2、brpoplpush/rpoplpush：Redis Brpoplpush 命令从列表中取出最后一个元素，并插入到另外一个列表的头部； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 BRPOPLPUSH msg reciver 500/BRPOPLPUSH LIST1 ANOTHER_LIST TIMEOUT 3、lindex：返回列表里的元素的索引 index 存储在 key 里面。 下标是从0开始索引的，所以 0 是表示第一个元素， 1 表示第二个元素，并以此类推。 负数索引用于指定从列表尾部开始索引的元素。在这种方法下，-1 表示最后一个元素，-2 表示倒数第二个元素，并以此往前推。 LINDEX mylist 0 4、linsert：把 value 插入存于 key 的列表中在基准值 pivot 的前面或后面。当 key 不存在时，这个list会被看作是空list，任何操作都不会发生。当 key 存在，但保存的不是一个list的时候，会返回error。 RPUSH mylist \"Hello\" (integer) 1 RPUSH mylist \"World\" (integer) 2 LINSERT mylist BEFORE \"World\" \"There\" (integer) 3 LRANGE mylist 0 -1 1) \"Hello\" 2) \"There\" 3) \"World\" 5、llen：返回存储在 key 里的list的长度。 如果 key 不存在，那么就被看作是空list，并且返回长度为 0。 当存储在 key 里的值不是一个list的话，会返回error。 LLEN mylist 其他命令： 1、LPOP key 移除并且返回 key 对应的 list 的第一个元素。 2、LPUSH key value [value ...] 将所有指定的值插入到存于 key 的列表的头部。如果 key 不存在，那么在进行 push 操作前会创建一个空列表。 如果 key 对应的值不是一个 list 的话，那么会返回一个错误。 3、LPUSHX key value 只有当 key 已经存在并且存着一个 list 的时候，在这个 key 下面的 list 的头部插入 value。 与 LPUSH 相反，当 key 不存在的时候不会进行任何操作。 4、LRANGE key start stop 返回存储在 key 的列表里指定范围内的元素。 start 和 end 偏移量都是基于0的下标，即list的第一个元素下标是0（list的表头），第二个元素下标是1，以此类推。 5、LREM key count value 从存于 key 的列表里移除前 count 次出现的值为 value 的元素。 这个 count 参数通过下面几种方式影响这个操作：count > 0: 从头往尾移除值为 value 的元素。count count = 0: 移除所有值为 value 的元素 6、LSET key index value 设置 index 位置的list元素的值为 value。 7、LTRIM key start stop 修剪(trim)一个已存在的 list，这样 list 就会只包含指定范围的指定元素。start 和 stop 都是由0开始计数的， 这里的 0 是列表里的第一个元素（表头），1 是第二个元素，以此类推。 8、RPOP key 移除并返回存于 key 的 list 的最后一个元素。 9、RPUSH key value [value ...] 向存于 key 的列表的尾部插入所有指定的值。如果 key 不存在，那么会创建一个空的列表然后再进行 push 操作。 当 key 保存的不是一个列表，那么会返回一个错误。 10、RPUSHX key value 将值 value 插入到列表 key 的表尾, 当且仅当 key 存在并且是一个列表。 和 RPUSH 命令相反, 当 key 不存在时，RPUSHX 命令什么也不做。 4.哈希（hash） 1、hdel：从 key 指定的哈希集中移除指定的域。在哈希集中不存在的域将被忽略。如果 key 指定的哈希集不存在，它将被认为是一个空的哈希集，该命令将返回0。 HDEL key field [field ...] 2、hexists：返回hash里面field是否存在 HEXISTS myhash field2 3、hget：返回 key 指定的哈希集中该字段所关联的值 HGET key field 4、hgetall：返回 key 指定的哈希集中所有的字段和值。 HGETALL myhash 5、hincrby/hincrbyfloat：增加 key 指定的哈希集中指定字段的数值。如果 key 不存在，会创建一个新的哈希集并与 key 关联。如果字段不存在，则字段的值在该操作执行前被设置为 0 HINCRBY 支持的值的范围限定在 64位 有符号整数 HINCRBY key field increment hincrby people age 1 6、hkeys：返回 key 指定的哈希集中所有字段的名字。 HKEYS key 7、hlen：返回 key 指定的哈希集包含的字段的数量。 HLEN key 8、hmget：返回 key 指定的哈希集中指定字段的值。 HMGET key field [field ...] 9、hmset：设置 key 指定的哈希集中指定字段的值。该命令将重写所有在哈希集中存在的字段。如果 key 指定的哈希集不存在，会创建一个新的哈希集并与 key 关联 HMSET key field value [field value ...] 10、hset：设置 key 指定的哈希集中指定字段的值。 HSET key field value 11、hsetnx：只在 key 指定的哈希集中不存在指定的字段时，设置字段的值。如果 key 指定的哈希集不存在，会创建一个新的哈希集并与 key 关联。如果字段已存在，该操作无效果。 HSETNX key field value 12、hstrlen：返回hash指定field的value的字符串长度，如果hash或者field不存在，返回0. HSTRLEN key field 13、hvals：返回 key 指定的哈希集中所有字段的值。 HVALS key 5.集合（set） 1、sadd：添加一个或多个指定的member元素到集合的 key中.指定的一个或者多个元素member 如果已经在集合key中存在则忽略.如果集合key 不存在，则新建集合key,并添加member元素到集合key中. SADD key member [member ...] 2、scard：返回集合存储的key的基数 (集合元素的数量). SCARD key 3、sdiff：返回一个集合与给定集合的差集的元素. SDIFF key [key ...] 4、sdiffstore：该命令类似于 SDIFF, 不同之处在于该命令不返回结果集，而是将结果存放在destination集合中. 如果destination已经存在, 则将其覆盖重写. SDIFFSTORE destination key [key ...] 5、sinter：返回指定所有的集合的成员的交集. SINTER key [key ...] 6、sinterstore：这个命令与SINTER命令类似, 但是它并不是直接返回结果集,而是将结果保存在 destination集合中. SINTERSTORE destination key [key ...] 7、sismember：返回成员 member 是否是存储的集合 key的成员. SISMEMBER key member 8、smembers：返回key集合所有的元素.该命令的作用与使用一个参数的SINTER 命令作用相同. SMEMBERS key 9、smove：将member从source集合移动到destination集合中. 对于其他的客户端,在特定的时间元素将会作为source或者destination集合的成员出现. SMOVE source destination member SMOVE myset myotherset \"two\" 10、spop：从存储在key的集合中移除并返回一个或多个随机元素。此操作与SRANDMEMBER类似，它从一个集合中返回一个或多个随机元素，但不删除元素。 SPOP key [count] 11、srandmember：那么随机返回key集合中的一个元素. SRANDMEMBER key [count] 12、srem：在key集合中移除指定的元素. 如果指定的元素不是key集合中的元素则忽略 如果key集合不存在则被视为一个空的集合，该命令返回0. SREM key member [member ...] 13、sunion：返回给定的多个集合的并集中的所有成员. SUNION key [key ...] 14、sunionstore：该命令作用类似于SUNION命令,不同的是它并不返回结果集,而是将结果存储在destination集合中.如果destination 已经存在,则将其覆盖. SUNIONSTORE destination key [key ...] 6.有序集合（sorted set） 1、zadd：将所有指定成员添加到键为key有序集合（sorted set）里面。 添加时可以指定多个分数/成员（score/member）对。 如果指定添加的成员已经是有序集合里面的成员，则会更新改成员的分数（scrore）并更新到正确的排序位置。 ZADD key [NX|XX] [CH] [INCR] score member [score member ...] 2、zcard：返回key的有序集元素个数。 ZCARD key 3、zcount：指定分数范围的元素个数。 ZCOUNT key min max 4、zincrby：为有序集key的成员member的score值加上增量increment。如果key中不存在member，就在key中添加一个member，score是increment（就好像它之前的score是0.0）。如果key不存在，就创建一个只含有指定member成员的有序集合 ZINCRBY key increment member 5、zintestore：计算给定的numkeys个有序集合的交集，并且把结果放到destination中。 在给定要计算的key和其它参数之前，必须先给定key个数(numberkeys)。 ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight] [SUM|MIN|MAX] redis> ZADD zset1 1 \"one\" (integer) 1 redis> ZADD zset1 2 \"two\" (integer) 1 redis> ZADD zset2 1 \"one\" (integer) 1 redis> ZADD zset2 2 \"two\" (integer) 1 redis> ZADD zset2 3 \"three\" (integer) 1 redis> ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 (integer) 2 redis> ZRANGE out 0 -1 WITHSCORES 1) \"one\" 2) \"5\" 3) \"two\" 4) \"10\" 6、zpopmax：删除并返回有序集合key中的最多count个具有最高得分的成员。 ZPOPMAX key [count] 7、zpopmin：删除并返回有序集合key中的最多count个具有最低得分的成员。 ZPOPMIN key [count] 8、zrange：返回存储在有序集合key中的指定范围的元素。 ZRANGE key start stop [WITHSCORES] 8、zrevrange：返回存储在有序集合key中的指定范围的元素。其中成员的位置按score值递减(从大到小)来排列。 ZREVRANGE key start stop [WITHSCORES] 9、zrank：返回有序集key中成员member的排名。 ZRANK key member 10、zrevrank：返回有序集key中成员member的排名，其中有序集成员按score值从大到小排列。排名以0为底，也就是说，score值最大的成员排名为0。 ZREVRANK key member 11、zrem：返回的是从有序集合中删除的成员个数，不包括不存在的成员。 ZREM key member [member ...] 7.地图（Geo） 1、geoadd：将指定的地理空间位置（纬度、经度、名称）添加到指定的key中。这些数据将会存储到sorted set这样的目的是为了方便使用GEORADIUS或者GEORADIUSBYMEMBER命令对数据进行半径查询等操作。 GEOADD key longitude latitude member [longitude latitude member ...] 2、geodist：返回两个给定位置之间的距离。如果两个位置之间的其中一个不存在， 那么命令返回空值。 GEODIST key member1 member2 [unit] 3、geohash：返回一个或多个位置元素的 Geohash 表示。 GEOHASH key member [member ...] 4、geopos：从key里返回所有给定位置元素的位置（经度和纬度）。 GEOPOS key member [member ...] 5、georadius：以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素 GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] 6、georadiusbymember：这个命令和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 GEORADIUSBYMEMBER 的中心点是由给定的位置元素决定的， 而不是像 GEORADIUS 那样， 使用输入的经度和纬度来决定中心点指定成员的位置被用作查询的中心。 GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] 8.HyperLogLog 1、pfadd：将除了第一个参数以外的参数存储到以第一个参数为变量名的HyperLogLog结构中. PFADD key element [element ...] PFADD hll a b c d e f g 2、pfcount：当参数为一个key时,返回存储在HyperLogLog结构体的该变量的近似基数，如果该变量不存在,则返回0. PFCOUNT key [key ...] PFCOUNT hll 3、pfmerge：将多个 HyperLogLog 合并（merge）为一个 HyperLogLog ， 合并后的 HyperLogLog 的基数接近于所有输入 HyperLogLog 的可见集合（observed set）的并集. PFMERGE destkey sourcekey [sourcekey ...] PFMERGE hll3 hll1 hll2 4、大量数据插入 data.txt文件 SET Key0 Value0 SET Key1 Value1 ... SET KeyN ValueN cat data.txt | redis-cli -h localhost -p 6380 -a liao --pipe unix2dos d1.txt 转码 cat d1.txt | redis-cli -h localhost -p 6380 -a liao [ --pipe ] 5、过期策略 Keys的过期时间 通常Redis keys创建时没有设置相关过期时间。他们会一直存在，除非使用显示的命令移除，例如，使用DEL命令。 EXPIRE一类命令能关联到一个有额外内存开销的key。当key执行过期操作时，Redis会确保按照规定时间删除他们。 key的过期时间和永久有效性可以通过EXPIRE和PERSIST命令（或者其他相关命令）来进行更新或者删除过期时间。 过期精度 在 Redis 2.4 及以前版本，过期期时间可能不是十分准确，有0-1秒的误差。 从 Redis 2.6 起，过期时间误差缩小到0-1毫秒。 过期和持久 Keys的过期时间使用Unix时间戳存储(从Redis 2.6开始以毫秒为单位)。这意味着即使Redis实例不可用，时间也是一直在流逝的。 要想过期的工作处理好，计算机必须采用稳定的时间。 如果你将RDB文件在两台时钟不同步的电脑间同步，有趣的事会发生（所有的 keys装载时就会过期）。 即使正在运行的实例也会检查计算机的时钟，例如如果你设置了一个key的有效期是1000秒，然后设置你的计算机时间为未来2000秒，这时key会立即失效，而不是等1000秒之后。 Redis如何淘汰过期的keys Redis keys过期有两种方式：被动和主动方式。 当一些客户端尝试访问它时，key会被发现并主动的过期。 当然，这样是不够的，因为有些过期的keys，永远不会访问他们。 无论如何，这些keys应该过期，所以定时随机测试设置keys的过期时间。所有这些过期的keys将会从密钥空间删除。 具体就是Redis每秒10次做的事情： 测试随机的20个keys进行相关过期检测。 删除所有已经过期的keys。 如果有多于25%的keys过期，重复步奏1. 这是一个平凡的概率算法，基本上的假设是，我们的样本是这个密钥控件，并且我们不断重复过期检测，直到过期的keys的百分百低于25%,这意味着，在任何给定的时刻，最多会清除1/4的过期keys。 在复制AOF文件时如何处理过期 为了获得正确的行为而不牺牲一致性，当一个key过期，DEL将会随着AOF文字一起合成到所有附加的slaves。在master实例中，这种方法是集中的，并且不存在一致性错误的机会。 然而，当slaves连接到master时，不会独立过期keys（会等到master执行DEL命令），他们任然会在数据集里面存在，所以当slave当选为master时淘汰keys会独立执行，然后成为master。 5、事务 MULTI 、 EXEC 、 DISCARD 和 WATCH 是 Redis 事务相关的命令。事务可以一次执行多个命令， 并且带有以下两个重要的保证： 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。 EXEC 命令负责触发并执行事务中的所有命令： 如果客户端在使用 MULTI 开启了一个事务之后，却因为断线而没有成功执行 EXEC ，那么事务中的所有命令都不会被执行。 另一方面，如果客户端成功在开启事务之后执行 EXEC ，那么事务中的所有命令都会被执行。 放弃事务 当执行 DISCARD 命令时， 事务会被放弃， 事务队列会被清空， 并且客户端会从事务状态中退出： WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。 被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回nil-reply来表示事务已经失败。 redis 主从分布配置操作步骤详解 主服务器：127.0.0.1 6379 从服务器：127.0.0.1 6380 1、首先，修改 Master上的如下配置（在 redis.conf 修改配置）：a. 禁用 主服务器 snapshot save 900 1 #禁用Snapshot save 300 10 save 60 10000 b. 禁用 AOF appendonly no #禁用AOF （该操作默认就是禁用的） c. 设置 master 密码 （可选） requirepass liao 2、修改 Slave（redis6666）上的如下配置： a. 启动 从服务器的 Snapshot save 900 1 #启用Snapshot （默认开启） save 300 10 save 60 10000 b. 启动 从服务器 AOF appendonly yes #启用AOF（默认关闭） appendfilename appendonly.aof #AOF文件的名称 c. 设置 slaveof slaveof 127.0.0.1 6379 masterauth liao 查看主服务器连接状态： info replication 四、 备份数据测试1、 Master 插入一条数据： 127.0.0.1:6666> set name helloworld OK 2、Slave 获取数据： 127.0.0.1:7777> get name \"helloworld\" 操作到这里： redis 主从配置成功了。 五、容灾机制测试1、Master 挂掉了： 127.0.0.1:6666> SHUTDOWN # 或者 直接 kill 掉 Master 进程 not connected> 2、 Slave 再次获取数据： 127.0.0.1:7777> get name \"helloworld\" 3、数据恢复 先在从服务器执行：save 将Slave上数据文件 dump.rdb 和 appendonly.aof 复制到 Master 目录上。 4、启动 Master ，分别在 Master 和 Slave 获取数据。 注意： 操作步骤3、4 不可互换，否则会造成数据丢失。 Master 启动后，Slave 会自动去同步数据。 Redis的过期策略我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。 过期策略通常有以下三种： 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。 定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。) Redis中同时使用了惰性过期和定期过期两种过期策略。 Redis的内存淘汰策略Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。 noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 1、前言 最近在项目中使用到Redis做缓存，方便多个业务进程之间共享数据。由于Redis的数据都存放在内存中，如果没有配置持久化，redis重启后数据就全丢失了，于是需要开启redis的持久化功能，将数据保存到磁盘上，当redis重启后，可以从磁盘中恢复数据。redis提供两种方式进行持久化，一种是RDB持久化（原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化），另外一种是AOF持久化（原理是将Reids的操作日志以追加的方式写入文件）。那么这两种持久化方式有什么区别呢，改如何选择呢？网上看了大多数都是介绍这两种方式怎么配置，怎么使用，就是没有介绍二者的区别，在什么应用场景下使用。 2、二者的区别 RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 3、二者优缺点 RDB存在哪些优势呢？ 1). 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 2). 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 3). 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。 4). 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。 RDB又存在哪些劣势呢？ 1). 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 2). 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。 AOF的优势有哪些呢？ 1). 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。 2). 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 3). 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 4). AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。 AOF的劣势有哪些呢？ 1). 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 2). 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。 二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。不过生产环境其实更多都是二者结合使用的。 4、常用配置 RDB持久化配置 Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息： save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。 save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。 save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。 AOF持久化配置 在Redis的配置文件中存在三种同步方式，它们分别是： appendfsync always #每次有数据修改发生时都会写入AOF文件。 appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。 appendfsync no #从不同步。高效但是数据不会被持久化。 "},"db/mongodb.html":{"url":"db/mongodb.html","title":"1.3 mongodb","keywords":"","body":"1. 安装 wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.9.tgz 下载最新版本tar -zxvf mongodb-linux-x86_64-4.0.9.tgz 解压源码mv mongodb-linux-x86_64-4.0.9 ../mongodb 进入目录vim /etc/profile source /etc/profile 配置 2. 配置说明 启动方式： mongod --dbpath=/data/db --port=27017 --fork --logpath=/home/logs/mongodb/mongod.log dbpath = /data/db logpath = /data/db/mongod.log logappend = true bind_ip = 0.0.0.0 port = 27017 fork = true 开启服务：mongod -f mongodb.conf 关闭服务：mongod -f mongodb.conf --shutdown 3. 存贮关系 数据库、集合、文档相当于mysql中数据库、表、记录的关系 4. 命令 1.数据库 1、创建数据库 use DATABASE_NAME use runoob db db.runoob.insert({\"name\":\"菜鸟教程\"}) 2、删除数据库 db.dropDatabase() 2.集合 1、创建集合 db.createCollection(name, options) db.createCollection(\"mycol\", { capped : true, autoIndexId : true, size : 6142800, max : 10000 } ) db.mycol2.insert({\"name\" : \"菜鸟教程\"}) #插入记录自动创建mycol2集合 字段 类型 描述 capped 布尔 （可选）如果为 true，则创建固定集合。固定集合是指有着固定大小的集合，当达到最大值时，它会自动覆盖最早的文档。当该值为 true 时，必须指定 size 参数。 autoIndexId 布尔 （可选）如为 true，自动在 _id 字段创建索引。默认为 false。 size 数值 （可选）为固定集合指定一个最大值（以字节计）。如果 capped 为 true，也需要指定该字段。 max 数值 （可选）指定固定集合中包含文档的最大数量。 在插入文档时，MongoDB 首先检查固定集合的 size 字段，然后检查 max 字段。 2、删除集合 db.collection.drop() db.mycol2.drop() 2.文档 1、插入文档 db.COLLECTION_NAME.insert(document) db.col.insert([{title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库',by: '菜鸟教程',url: 'http://www.runoob.com',tags: ['mongodb', 'database', 'NoSQL'],likes: 100},{title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库',by: '菜鸟教程',url: 'http://www.runoob.com',tags: ['mongodb', 'database', 'NoSQL'],likes: 100}]) db.col.insert([{},{}]) #插入多个 db.collection.insertOne({\"a\": 3}) db.collection.insertMany([{\"b\": 3}, {'c': 4}]) 2、更新文档 db.collection.update(,,{upsert: ,multi: ,writeConcern: }) db.collection.save(,{writeConcern: }) //以下实例中我们替换了 _id 为 56064f89ade2f21f36b03136 的文档数据： 3、删除文档 db.collection.remove(,{justOne: ,writeConcern: }) db.col.remove({\"title\":\"mongodb\"},{\"justOne\":true}) //db.col.deleteMany({ status : \"A\" }) |db.col.deleteOne( { status: \"D\" } ) db.col.remove({}) //删除所有数据 |db.col.deleteMany({}) db.repairDatabase() //回收磁盘空间 db.runCommand({ repairDatabase: 1 }) //回收磁盘空间 4、查询文档 db.collection.find(query, projection) db.col.find().pretty() db.col.find({\"likes\":{$lte:50}}).pretty() db.col.find({key1:value1, key2:value2}).pretty() //and db.col.find({$or: [{key1: value1}, {key2:value2}]}).pretty() //or db.col.find({\"likes\": {$gt:50}, $or: [{\"by\": \"菜鸟教程\"},{\"title\": \"MongoDB 教程\"}]}).pretty() db.col.find({title:/教/}) db.col.find({title:/^教/}) db.col.find({title:/教$/}) db.col.find({\"title\" : {$type : 'string'}}) db.COLLECTION_NAME.find().limit(NUMBER) db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER) 在 MongoDB 中使用 sort() 方法对数据进行排序，sort() 方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而 -1 是用于降序排列。 db.COLLECTION_NAME.find().sort({KEY:1}) 操作 格式 范例 RDBMS中的类似语句 等于 {:} db.col.find({\"by\":\"菜鸟教程\"}).pretty() where by = '菜鸟教程' 小于 {:{$lt:}} db.col.find({\"likes\":{$lt:50}}).pretty() where likes 小于或等于 {:{$lte:}} db.col.find({\"likes\":{$lte:50}}).pretty() where likes 大于 {:{$gt:}} db.col.find({\"likes\":{$gt:50}}).pretty() where likes > 50 大于或等于 {:{$gte:}} db.col.find({\"likes\":{$gte:50}}).pretty() where likes >= 50 不等于 {:{$ne:}} db.col.find({\"likes\":{$ne:50}}).pretty() where likes != 50 5、索引 db.collection.createIndex(keys, options) db.col.createIndex({\"title\":1,\"description\":-1}) 字段 类型 描述 background Boolean 建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引，即增加 \"background\" 可选参数。 \"background\" 默认值为false。 unique Boolean 建立的索引是否唯一。指定为true创建唯一索引。默认值为false. name string 索引的名称。如果未指定，MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称。 sparse Boolean 对文档中不存在的字段数据不启用索引；这个参数需要特别注意，如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档.。默认值为 false. expireAfterSeconds integer 指定一个以秒为单位的数值，完成 TTL设定，设定集合的生存时间。 v index version 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本。 weights document 索引权重值，数值在 1 到 99,999 之间，表示该索引相对于其他索引字段的得分权重。 default_language string 对于文本索引，该参数决定了停用词及词干和词器的规则的列表。 默认为英语 language_override string 对于文本索引，该参数指定了包含在文档中的字段名，语言覆盖默认的language，默认值为 language. 6、聚合 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$sum : 1}}}]) //等同于下 select by_user, count(*) from mycol group by by_user 表达式 描述 实例 $sum 计算总和。 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$sum : \"$likes\"}}}]) $avg 计算平均值 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$avg : \"$likes\"}}}]) $min 获取集合中所有文档对应值得最小值。 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$min : \"$likes\"}}}]) $max 获取集合中所有文档对应值得最大值。 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$max : \"$likes\"}}}]) $push 在结果文档中插入值到一个数组中。 db.mycol.aggregate([{$group : {_id : \"$by_user\", url : {$push: \"$url\"}}}]) $addToSet 在结果文档中插入值到一个数组中，但不创建副本。 db.mycol.aggregate([{$group : {_id : \"$by_user\", url : {$addToSet : \"$url\"}}}]) $first 根据资源文档的排序获取第一个文档数据。 db.mycol.aggregate([{$group : {_id : \"$by_user\", first_url : {$first : \"$url\"}}}]) $last 根据资源文档的排序获取最后一个文档数据 db.mycol.aggregate([{$group : {_id : \"$by_user\", last_url : {$last : \"$url\"}}}]) 7、备份与恢复mongodb操作命令： mongodump -h 192.168.0.171:5000 -d game -o ./back 导出 mongodump -h 192.168.0.171:5000 -o /data/wwwroot/jpoa.ifanspoker.com/tmp/backmongo 导出 mongorestore -h localhost:27017 -d game ./game 导入 mongorestore -h localhost:27017 /备份位置 8、ObjectIdObjectId 是一个12字节 BSON 类型数据，有以下格式： 前4个字节表示时间戳接下来的3个字节是机器标识码紧接的两个字节由进程id组成（PID）最后三个字节是随机数。MongoDB中存储的文档必须有一个\"_id\"键。这个键的值可以是任何类型的，默认是个ObjectId对象。在一个集合里面，每个文档都有唯一的\"_id\"值，来确保集合里面每个文档都能被唯一标识。MongoDB采用ObjectId，而不是其他比较常规的做法（比如自动增加的主键）的主要原因，因为在多个 服务器上同步自动增加主键值既费力还费时。 newObjectId = ObjectId() ObjectId(\"5349b4ddd2781d08c09890f4\").getTimestamp() new ObjectId().str "},"db/sqlite3.html":{"url":"db/sqlite3.html","title":"1.4 sqlite3","keywords":"","body":"0. 介绍 SQLite 是一个软件库，实现了自给自足的、无服务器的、零配置的、事务性的 SQL 数据库引擎。SQLite 是在世界上最广泛部署的 SQL 数据库引擎。 1. 安装 tar xvzf sqlite-autoconf-3071502.tar.gz 解压源码cd sqlite-autoconf-3071502 进入目录./configure --prefix=/usr/localmake && make install 编译安装 2. 配置说明 进入服务:sqlite3 3. 命令 1.数据库 sqlite3 DatabaseName.db //创建数据库 sqlite>.databases //检查数据库 sqlite>.quit //退出 sqlite3 rule.db .dump > aa.sql //导出数据库成sql语句 sqlite3 tools.db 2.附加数据库 假设这样一种情况，当在同一时间有多个数据库可用，您想使用其中的任何一个。SQLite 的 ATTACH DATABASE 语句是用来选择一个特定的数据库，使用该命令后，所有的 SQLite 语句将在附加的数据库下执行。 sqlite>ATTACH DATABASE 'DatabaseName' As 'Alias-Name'; sqlite> ATTACH DATABASE 'testDB.db' as 'TEST'; 注：数据库名称 main 和 temp 被保留用于主数据库和存储临时表及其他临时数据对象的数据库。 3.分离数据库 SQLite的 DETACH DTABASE 语句是用来把命名数据库从一个数据库连接分离和游离出来，连接是之前使用 ATTACH 语句附加的。如果同一个数据库文件已经被附加上多个别名，DETACH 命令将只断开给定名称的连接，而其余的仍然有效。您无法分离 main 或 temp 数据库。 sqlite>DETACH DATABASE 'Alias-Name'; sqlite>DETACH DATABASE 'TEST'; 4.创建表/删除表 CREATE TABLE database_name.table_name( column1 datatype PRIMARY KEY(one or more columns), column2 datatype, column3 datatype, ..... columnN datatype, ); create table yh_user( id INTEGER primary key autoincrement, username varchar(255) default '', password char(32) default '', real_name varchar(20) default '', sex tinyint default 0 ); DROP TABLE database_name.table_name; 查看表信息 sqlite> SELECT sql FROM sqlite_master WHERE type = 'table' AND tbl_name = 'COMPANY'; 5.数据类型 SQLite 数据类型是一个用来指定任何对象的数据类型的属性。SQLite 中的每一列，每个变量和表达式都有相关的数据类型。您可以在创建表的同时使用这些数据类型。SQLite 使用一个更普遍的动态类型系统。在 SQLite 中，值的数据类型与值本身是相关的，而不是与它的容器相关。 SQLite 存储类 每个存储在 SQLite 数据库中的值都具有以下存储类之一： 存储类 描述 NULL 值是一个 NULL 值。 INTEGER 值是一个带符号的整数，根据值的大小存储在 1、2、3、4、6 或 8 字节中。 REAL 值是一个浮点值，存储为 8 字节的 IEEE 浮点数字。 TEXT 值是一个文本字符串，使用数据库编码（UTF-8、UTF-16BE 或 UTF-16LE）存储。 BLOB 值是一个 blob 数据，完全根据它的输入存储。 SQLite 亲和(Affinity)类型SQLite支持列的亲和类型概念。任何列仍然可以存储任何类型的数据，当数据插入时，该字段的数据将会优先采用亲缘类型作为该值的存储方式。SQLite目前的版本支持以下五种亲缘类型： 亲和类型 描述 TEXT 数值型数据在被插入之前，需要先被转换为文本格式，之后再插入到目标字段中。 NUMERIC 当文本数据被插入到亲缘性为NUMERIC的字段中时，如果转换操作不会导致数据信息丢失以及完全可逆，那么SQLite就会将该文本数据转换为INTEGER或REAL类型的数据，如果转换失败，SQLite仍会以TEXT方式存储该数据。对于NULL或BLOB类型的新数据，SQLite将不做任何转换，直接以NULL或BLOB的方式存储该数据。需要额外说明的是，对于浮点格式的常量文本，如\"30000.0\"，如果该值可以转换为INTEGER同时又不会丢失数值信息，那么SQLite就会将其转换为INTEGER的存储方式。 INTEGER 对于亲缘类型为INTEGER的字段，其规则等同于NUMERIC，唯一差别是在执行CAST表达式时。 REAL 其规则基本等同于NUMERIC，唯一的差别是不会将\"30000.0\"这样的文本数据转换为INTEGER存储方式。 NONE 不做任何的转换，直接以该数据所属的数据类型进行存储。　　 SQLite 亲和类型(Affinity)及类型名称下表列出了当创建 SQLite3 表时可使用的各种数据类型名称，同时也显示了相应的亲和类型： 数据类型 亲和类型 INT、INTEGER、TINYINT、SMALLINT、MEDIUMINT、BIGINT、UNSIGNED、BIG、INT、INT2、INT8 INTEGER CHARACTER(20)、VARCHAR(255)、VARYING、CHARACTER(255)、NCHAR(55)、NATIVE、CHARACTER(70)、NVARCHAR(100)、TEXT、CLOB TEXT BLOB、no datatype specified NONE REAL、DOUBLE、DOUBLE、PRECISION、FLOAT REAL NUMERIC、DECIMAL(10,5)、BOOLEAN、DATE、DATETIME NUMERIC　 6.命令 Insert、Select、Update、Delete、Like、Glob、Distinct、Limit、Having 交叉连接 ： CROSS JOIN交叉连接（CROSS JOIN）把第一个表的每一行与第二个表的每一行进行匹配。如果两个输入表分别有 x 和 y 行，则结果表有 x*y 行。由于交叉连接(CROSS JOIN)有可能产生非常大的表，使用时必须谨慎，只在适当的时候使用它们。 select emp_id, name, dept from company cross join department; 内连接 ： INNER JOIN 内连接（INNER JOIN）根据连接谓词结合两个表（table1 和 table2）的列值来创建一个新的结果表。查询会把 table1 中的每一行与 table2 中的每一行进行比较，找到所有满足连接谓词的行的匹配对。当满足连接谓词时，A 和 B 行的每个匹配对的列值会合并成一个结果行。 select emp_id, name, dept from company inner join department on company.id = department.emp_id; 外连接 ：OUTER JOIN外连接（OUTER JOIN）是内连接（INNER JOIN）的扩展。虽然 SQL 标准定义了三种类型的外连接：LEFT、RIGHT、FULL，但 SQLite 只支持 左外连接（LEFT OUTER JOIN）。 select emp_id, name, dept from company left outer join department on company.id = department.emp_id; Unions 子句 SQLite的 UNION 子句/运算符用于合并两个或多个 SELECT 语句的结果，不返回任何重复的行。 为了使用 UNION，每个 SELECT 被选择的列数必须是相同的，相同数目的列表达式，相同的数据类型，并确保它们有相同的顺序，但它们不必具有相同的长度。 UNION ALL 运算符用于结合两个 SELECT 语句的结果，包括重复行。 适用于 UNION 的规则同样适用于 UNION ALL 运算符。 sqlite> SELECT EMP_ID, NAME, DEPT FROM COMPANY INNER JOIN DEPARTMENT ON COMPANY.ID = DEPARTMENT.EMP_ID UNION SELECT EMP_ID, NAME, DEPT FROM COMPANY LEFT OUTER JOIN DEPARTMENT ON COMPANY.ID = DEPARTMENT.EMP_ID; TRUNCATE TABLE//等同于下面数据 DELETE FROM table_name; DELETE FROM sqlite_sequence WHERE name = 'table_name'; UPDATE sqlite_sequence SET seq = 0 WHERE name = 'table_name'; 7.SQLite 约束 NOT NULL 约束：确保某列不能有 NULL 值。 DEFAULT 约束：当某列没有指定值时，为该列提供默认值。 UNIQUE 约束：确保某列中的所有值是不同的。 PRIMARY Key 约束：唯一标识数据库表中的各行/记录。 CHECK 约束：CHECK 约束确保某列中的所有值满足一定条件。 CREATE TABLE COMPANY3( ID INT PRIMARY KEY NOT NULL DEFAULT 0, NAME TEXT NOT NULL UNIQUE, AGE INT NOT NULL DEFAULT 0, ADDRESS CHAR(50), SALARY REAL CHECK(SALARY > 0) ); CREATE TABLE table_name( column1 INTEGER AUTOINCREMENT, column2 datatype, column3 datatype, ..... columnN datatype, ); 8.索引（Index） 索引（Index）是一种特殊的查找表，数据库搜索引擎用来加快数据检索。简单地说，索引是一个指向表中数据的指针。一个数据库中的索引与一本书后边的索引是非常相似的。 CREATE INDEX index_name ON table_name; //单列索引 CREATE INDEX index_name ON table_name (column_name); //唯一索引 CREATE UNIQUE INDEX index_name on table_name (column_name); //联合索引 CREATE INDEX index_name on table_name (column1, column2); //查看表索引 .indices COMPANY //删除索引 DROP INDEX index_name; 什么情况下要避免使用索引？ 虽然索引的目的在于提高数据库的性能，但这里有几个情况需要避免使用索引。使用索引时，应重新考虑下列准则： 索引不应该使用在较小的表上。 索引不应该使用在有频繁的大批量的更新或插入操作的表上。 索引不应该使用在含有大量的 NULL 值的列上。 索引不应该使用在频繁操作的列上。 "},"db/mysql.html":{"url":"db/mysql.html","title":"1.5 mysql","keywords":"","body":"1. 安装mysql基础操作 1.数据库基础操作 mysql -u用户名 -p密码 [--tee=d:\\mysql.log] 登录mysql客户端 show databases; 查看所有的数据库 use database; 切换到某数据库 show tables; 查看某数据库下面的所有表 \\s 或 status 查看数据库的状态 2.数据库操作 show databases; 查看数据库 create database 数据库名; 创建数据库 drop database 数据库名; 删除数据库 show create database 数据库名 查看数据库创建情况 show create table 表名 查看表的创建情况 例：create database test default character set utf8; create database jdbc default charset=utf8; create database if not exists test default charset utf8 collate utf8_general_ci; 3.数据表操作 show tables； 查看数据表 create table 表名( int 属性, name 属性, age 属性 ) 创建数据表 drop table 表名 删除数据表 rename table old表名 to new表名 修改数据表表名 desc 表名 查看表结构 forexample: CREATE TABLE IF NOT EXISTS `member` ( `id` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '编号', `user` varchar(20) NOT NULL, `passwd` char(40) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 4.数据库设计 a)字段类型 数值：int,float 字符：varchar,char,text,logntext 日期：date,datetime,time b)字段属性 unsigned zerofill auto_increment null not null default alter table 表名 default character set 字符集 //修改表的默认字符集 alter table 表名 CONVERT TO CHARACTER SET charset_name; //修改表的字符集包括列 5.字符集设置 my.ini [mysqld]服务器 character-set-server = utf8 //服务器、数据库和表字符集 collation-server = utf8_general_ci //服务器、数据库和表校验字符集 [mysql]客户端 default-character-set=utf8 //客户端和连接字符集 6.表字段索引 desc select * from 表名 where field = ''\\G; 创建带索引的表： create table t1( id int unsigned not null auto_increment, name varchar(20), primary key (id), index in_name(name) || key(name) )engine=InnoDB default character set utf8; show index from table_name; //查看索引情况 ？[参数] //查看某帮助信息 普通索引：1.添加 alter table 表名 add index in_name(field); alter table 表名 add key(field); 2.删除 alter table 表名 drop index in_name; a;ter table 表名 drop key(field) 7.表字段维护 1.添加字段 alter table 表名 add field 属性 after field; 2.修改字段 alter table 表名 modify field 属性 3.删除字段 alter table 表名 drop field 4.修改字段名 alter table 表名 change oldfield newfield 属性 8.mysql操作语句 1.concat() for: select id,name,concat(id,'--',name) as newfield from table_name; 2.rand() for: select id,name,rand()*2 as newfield from table_name; 3.sum() 4.avg() 5.max() 6.min() 7.distinct 去重复 select distinct * from table_name; 7.分组聚合 for: a)select name,count(id) as newfield from table_name group by name order by newfield asc; b)select name,count(id) as newfield from table_name group by name having newfield>5 order by newfield asc; 8.多表查询 a)普通多表查询 for: select name,count(name) as num from user as u,post as p where u.id=p.u_id group by u.name; b)嵌套查询-多表 for:select name from user where id in (select distinct u_id from post); c)左连接查询-多表 for:select a.name,b.title from user as a left join post as b on a.id=b.u_id; drop table if exists p_user; create table p_user( id bigint(20) unsigned not null auto_increment primary key comment '编号', u_name varchar(20) null comment '姓名', u_spell text comment '姓名拼音', key u_name(u_name) )engine=InnoDB default charset=utf8 comment='人员表'; desc p_user; show create table p_user; DROP TABLE IF EXISTS `tdl_workshop_daily_two_config`; CREATE TABLE IF NOT EXISTS `tdl_workshop_daily_two_config`( `twt_id` BIGINT(20) UNSIGNED NOT NULL DEFAULT '0' PRIMARY KEY COMMENT '主键', `twd_id` BIGINT(20) UNSIGNED NOT NULL DEFAULT '0' COMMENT '主表主键', `did` BIGINT(20) UNSIGNED NULL COMMENT '值班地点' )ENGINE=MYISAM ROW_FORMAT=DYNAMIC DEFAULT CHARSET=utf8 COMMENT='车间日报配置主表-值班地点' mysql更改密码： 1. update mysql.user set password = password('newpasswd') where user = '用户名'; //修改密码 2. flush privileges; //刷新数据库 或 3. grant select,insert,update,delete,show_db on 数据库名.* to 用户名@\"主机名\" Identified by \"密码\"; mysqlcheck使用： 1. mysqlcheck -r -u root -p -A 修复所有的表 2. mysqlcheck -r -u root -p db_name table_name 修复某数据库的某表 CREATE DATABASE db_name DEFAULT CHARACTER SET latin1 COLLATE latin1_swedish_ci; 数据库事物：1.原子性：不可分割。2.一致性：事物必须使数据库从一个一致性状态变换到另一个一致性状态。3.隔离性：不被其他事物干扰。4.持久性：一个事物一旦被提交，它对数据库数据的改变就是永久性的。 问题：1.脏读：2.不可重复读3.幻读 "},"php/php.html":{"url":"php/php.html","title":"2. PHP篇","keywords":"","body":"空着，待写…… "},"php/base.html":{"url":"php/base.html","title":"2.1 基础语法","keywords":"","body":"PHP基础语法 1、PHP引用传值 1.1 zval容器 1.2 xdebug扩展 1.3 对象引用 1.4 其他 1.5 案例 2、PHP运算符优先级 2.1 zval容器 2.2 xdebug扩展 2.3 对象引用 2.4 其他 2.5 案例 "},"php/base/base-1.html":{"url":"php/base/base-1.html","title":"2.1.1 PHP基础","keywords":"","body":"PHP基础语法 1、PHP引用传值 1.1 zval容器 1.2 xdebug扩展 1.3 对象引用 class abc { public $name = 'yang'; } $a = new abc(); xdebug_debug_zval('a'); $b = $a; $b->name = 'liao'; xdebug_debug_zval('a'); a: (refcount=1, is_ref=0)=class abc { public $name = (refcount=2, is_ref=0)='yang' } a: (refcount=2, is_ref=0)=class abc { public $name = (refcount=0, is_ref=0)='liao' } 1.4 其他 1.5 案例 $arr = [\"a\",\"b\",\"c\"]; foreach ($arr as $k => $v) { $v = &$arr[$k]; xdebug_debug_zval('arr'); } print_r($arr); array(\"b\",\"c\",\"c\") 2、PHP运算符优先级 2.1 zval容器 2.2 xdebug扩展 2.3 对象引用 2.4 其他 2.5 案例 3、PHP缓存 APC （Alternative PHP Cache（APC PHP缓存加速器）） Alternative PHP Cache (APC) 中文全称是“可选PHP缓存加速器”，是一种对PHP有效的开放源高速缓冲储存器工具，可用于缓存和优化Web服务器上的PHP代码，改善服务器性能。 APCu被APC剥离了操作码缓存。 第一个APCu代码库的​​版本是4.0.0，它当时是从APC主分支的负责人那里分出来的。 从APCu 5.0.0开始提供PHP 7支持。 APCu可以提供兼容模式，以便它可以替代APC的适用部分。 OPcache OPcache 通过将 PHP 脚本预编译的字节码存储到共享内存中来提升 PHP 的性能， 存储预编译字节码的好处就是 省去了每次加载和解析 PHP 脚本的开销。 opcache.memory_consumption=128 opcache.interned_strings_buffer=8 opcache.max_accelerated_files=4000 opcache.revalidate_freq=60 opcache.fast_shutdown=1 opcache.enable_cli=1 "},"php/base/base-2.html":{"url":"php/base/base-2.html","title":"2.1.2 php7的生命周期","keywords":"","body":"php7的生命周期 1.模块初始化阶段(module startup) 这个阶段主要进行php框架、zend引擎的初始化操作。该阶段的入口函数为php_module_startup()，这个阶段一般是在SAPI启动时执行一次，对于FPM而言，就是在fpm的master进行启动时执行的。 该阶段的几个主要处理如下所诉: 1.激活SAPI:sapi_activate(),初始化请求信息SG(request_info)、设置读取POST请求的handel等，在module_startup阶段处理完成后将调用sapi_activate() 2.启动php输出 php_output_startup 3.初始化垃圾回收期：gc_globals_ctor(),分配zend_gc_globals内存 4.启动Zedn引擎 zend_startup,主要操作包括: a.启动内存池 start_memory_manager() b.设置一些util函数句柄(如zend_error_cb.zend_printf.zend_write) c.设置Zend虚拟机编译、执行器的函数句柄zend_compile_file,zend_execute_ex,以及垃圾回收的函数句柄gc_collect_cycles d.分配函数符号表(CG(function_table))、类符号表(CG(class_table))、常量符号表(EG(zend_constants))等，如果是多线程的话，还会分配编译器、执行器的全局变量 e.注册zend核心扩展:zend_startup_builtin_functions()，这个扩展是内核提供的，该过程将注册zend核心扩展提供的函数，比如strlen.define.func_get_args.class_exists等 f.注册zend定义的标准常量：zend_register_standard_constants()，比如E_ERROR.E_WARNING.E_ALL.TRUE.FALSE等 g.注册$GLOBALS超全局变量的获取handler h.分配php.ini配置的存储符号表 EG(ini_directives) 5.注册php定义的常量,PHP_VERSION.PHP_ZTS.PHP_SAPI等 6.解析php.ini，解析完成后所有的php.ini配置保存在configuration_hash哈希表中。 7.映射php、zend核心的php.ini配置：根据解析出的php.ini，获取对应的配置值，将最终的配置插入EG(ini_directives) 哈希表 8.注册用户获取$_GET.$_POST.$_COOKIE.$_SERVER.$_ENV.$_REQUEST.$_FILES变量的handler 9.注册静态编译的扩展:php_register_internal_extensions_func() 10.注册动态加载的扩展:php_ini_register_extensions()，将php.ini中配置的扩展加载到php中 11.回调各扩展定义的module startup钩子函数，即通过PHP_MINT_FUNCTION()定义的函数 12.注册php.ini中禁用的函数、类，disable_functions.disbale_classes. 2.请求初始化阶段(request startup) 该阶段是在请求处理前每一个请求都会经历的一个阶段，对于fpm而言，是在worker进程accept一个请求并读取、解析完请求数据后的一个阶段。该阶段的处理函数为php_request_startup() 主要的处理有以下几个: 1.激活输出:php_output_activate() 2.激活zend引擎 zend_activate，主要操作如下所述 a.重置垃圾回收器 gc_reset() b.初始化编译器:init_compiler() c.初始化执行器:init_executor，将EG(function_table)、EG(clas_table)分配指向CG(function_table)、CG(class_table),所以在php的编译、执行同期，EG(function_table)与CG(function_table)、EG(clas_table)与CG(class_table)是同一个值；另外还会初始化全局变量符号表EG(symbol_table)、include过的文件符号表EG(included_files); d.初始化词法扫描器:startup_scanner() f.激活SAPI：sapi_activate() g.回调各扩展定义的request startup钩子函数 zend_activate_modules() 3.执行脚本阶段(execute script) 该极端包括php代码的编译、执行两个核心阶段,这也是zend引擎最重要的功能。在编译阶段，php脚本将经历从php源代码抽象语法树再到opline指令的转化过程，最终生成的opline指令就是zend引擎可识别的执行指令，这些指令接着被执行器执行，这就是php代码解释执行的过程。这个接口的入口函数为php_execute_script() 4.请求关闭阶段(request shutdown) 在php脚本执行解释器执行完成后将进入请求关闭阶段，这个阶段将flush输出内容、发送http应答header头、清理全局变量、关闭编译器、关闭执行器等。另外，在该阶段将回调各扩展的request shutdown钩子函数。该阶段是请求初始化阶段的相反操作，与请求初始化时的处理一一对应 5.模块关闭阶段(module shutdown) 该阶段在SAPI关闭时执行，与模块初始化阶段对应，这个阶段主要是进行资源的清理、php各模块的关闭操作，同时，将回调各扩展的module shutdown钩子函数。具体的处理函数为 php_module_shutdown() "},"php/base/base-3.html":{"url":"php/base/base-3.html","title":"2.1.3 PHP中缓存技术总结","keywords":"","body":"PHP中9大缓存技术总结 1、全页面静态化缓存 也就是将页面全部生成html静态页面，用户访问时直接访问的静态页面，而不会去走php服务器解析的流程。此种方式，在CMS系统中比较常见，比如dedecms； 一种比较常用的实现方式是用输出缓存： Ob_start() **要运行的代码* $content = Ob_get_contents(); 将缓存内容写入html文件* Ob_end_clean(); 2、页面部分缓存 该种方式，是将一个页面中不经常变的部分进行静态缓存，而经常变化的块不缓存，最后组装在一起显示；可以使用类似于ob_get_contents 的方式实现，也可以利用类似ESI之类的页面片段缓存策略，使其用来做动态页面中相对静态的片段部分的缓存 任何一个Web网站的内容都是在不断更新和变化，但这并不意味这这个网站的内容就是动态内容，事实上，动态的内容是指用户每次点击 相同的链接时取的的内容是由Web服务器应用程序生成的，如常见得ASP，JSP等，与此相对应，静态内容一般就是指由文本、图像和多媒体组成，在用户每 次单击相应链接时基本保持不变。现在解决动态内容缓存的最新技术就是通过ESI技术来设计网站的内容。 ESI技术工作原理 动态生成的内容能为用户带来丰富精彩的页面，网站开发者也可以更容易和更灵活地控制相关的内容，但在享受这些便利的同时，也增加了 网站数据库和应用服务器的处理压力的。当网站的访问量增大后，硬件和数据库的投资是非常巨大的，即使如此，仍然有可能导致页面的严重延迟甚至访问失败。 用户访问动态生成的内容速度慢的根本原因在于动态生成的内容需要经过一个复杂的过程，首先，根据用户请求的不同将用户的请求分配 到应用服务器相应的软件模块中，软件模块必须通过运算决定需要从数据库中提取什么样的数据给用户，然后再从数据库中提取出相应的数据按照定义的格式传给用 户。这些冗长的过程导致用户访问速度变慢，同时增加了服务器的负载。 在实际环境中，一个动态生成的页面，当中可能只有少量的内容是频繁变化的或是个性化的，对于传统的Cache服务器来说，为了能 够保证页面的时效性，却由于页面中这些少量的动态内容而无法将整个页面进行缓存。ESI（Edge Side Include）通过使用简单的标记语言来对那些可以加速和不能加速的网页中的内容片断进行描述，每个网页都被划分成不同的小部分分别赋予不同的缓存控制 策略，使Cache服务器可以根据这些策略在将完整的网页发送给用户之前将不同的小部分动态地组合在一起。通过这种控制，可以有效地减少从服务器抓取整个 页面的次数，而只用从原服务器中提取少量的不能缓存的片断，因此可以有效降低原服务器的负载，同时提高用户访问的响应时间。 ESI是一种简单的标识语言，开发人员可以使用它标志内容片断以便通过相应的Cache服务器来加速缓存。同时ESI还定义了一 套内容效验标准，可以实现原服务器对Cache服务器中缓存内容的管理，提高了网站对内容的控制能力。CDN网络也可以利用在分布全国各地的节点中安装支 持ESI的Cache服务器来提供对网站动态内容提供CDN服务。 该种方式可以用于如商城中的商品页； 3、数据缓存 顾名思义，就是缓存数据的一种方式；比如，商城中的某个商品信息，当用商品id去请求时，就会得出包括店铺信息、商品信息等数据，此时就可以将这些 数据缓存到一个php文件中，文件名包含商品id来建一个唯一标示；下一次有人想查看这个商品时，首先就直接调这个文件里面的信息，而不用再去数据库查 询；其实缓存文件中缓存的就是一个php数组之类； Ecmall商城系统里面就用了这种方式； 4、查询缓存 其实这跟数据缓存是一个思路，就是根据查询语句来缓存；将查询得到的数据缓存在一个文件中，下次遇到相同的查询时，就直接先从这个文件里面调数据，不会再去查数据库；但此处的缓存文件名可能就需要以查询语句为基点来建立唯一标示； 按时间变更进行缓存 其实，这一条不是真正的缓存方式；上面的2、3、4的缓存技术一般都用到了时间变更判断；就是对于缓存文件您需要设一个有效时间，在这个有效时间 内，相同的访问才会先取缓存文件的内容，但是超过设定的缓存时间，就需要重新从数据库中获取数据，并生产最新的缓存文件；比如，我将我们商城的首页就是设 置2个小时更新一次； 5、按内容变更进行缓存 这个也并非独立的缓存技术，需结合着用；就是当数据库内容被修改时，即刻更新缓存文件； 比如，一个人流量很大的商城，商品很多，商品表必然比较大，这表的压力也比较重；我们就可以对商品显示页进行页面缓存； 当商家在后台修改这个商品的信息时，点击保存，我们同时就更新缓存文件；那么，买家访问这个商品信息时，实际上访问的是一个静态页面，而不需要再去访问数据库； 试想，如果对商品页不缓存，那么每次访问一个商品就要去数据库查一次，如果有10万人在线浏览商品，那服务器压力就大了； 6、内存式缓存 提到这个，可能大家想到的首先就是Memcached；memcached是高性能的分布式内存缓存服务器。 一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度、 提高可扩展性。 它就是将需要缓存的信息，缓存到系统内存中，需要获取信息时，直接到内存中取；比较常用的方式就是 key–>value方式； connect($memcachehost,$memcacheport) or die (\"Could not connect\"); $memcache->set('key','缓存的内容'); $get = $memcache->get($key); //获取信息 ?> 7、apache缓存模块 apache安装完以后，是不允许被cache的。如果外接了cache或squid服务器要求进行web加速的话，就需要在htttpd.conf里进行设置，当然前提是在安装apache的时候要激活mod_cache的模块。 安装apache时：./configure –enable-cache –enable-disk-cache –enable-mem-cache 8、php APC缓存扩展 APC （Alternative PHP Cache（APC PHP缓存加速器）） Alternative PHP Cache (APC) 中文全称是“可选PHP缓存加速器”，是一种对PHP有效的开放源高速缓冲储存器工具，可用于缓存和优化Web服务器上的PHP代码，改善服务器性能。 APCu被APC剥离了操作码缓存。 第一个APCu代码库的​​版本是4.0.0，它当时是从APC主分支的负责人那里分出来的。 从APCu 5.0.0开始提供PHP 7支持。 APCu可以提供兼容模式，以便它可以替代APC的适用部分。 [apcu] apc.enabled=1 apc.shm_segments = 1 apc.shm_size=32M apc.ttl=0 apc.enable_cli=1 apc.entries_hint=0 apc.gc_ttl = 3600 apc.rfc1867 = off apc.slam_defense = off apc.use_request_time = 0 9、Opcode缓存 OPcache 通过将 PHP 脚本预编译的字节码存储到共享内存中来提升 PHP 的性能， 存储预编译字节码的好处就是 省去了每次加载和解析 PHP 脚本的开销。 首先php代码被解析为Tokens，然后再编译为Opcode码，最后执行Opcode码，返回结果；所以，对于相同的php文件，第一次运行时 可以缓存其Opcode码，下次再执行这个页面时，直接会去找到缓存下的opcode码，直接执行最后一步，而不再需要中间的步骤了。 [opcache] opcache.enable=1 #启动操作码缓存 opcache.enable_cli=1 #针对支持CLI版本PHP启动操作码缓存 一般被用来测试和调试 opcache.memory_consumption=128 #共享内存大小，单位为MBopcache.interned_strings_buffer=8 #存储临时字符串缓存大小，单位为MB，PHP5.3.0以前会忽略此项配置 opcache.max_accelerated_files=4000 #缓存文件数最大限制，命中率不到100%，可以试着提高这个值 opcache.revalidate_freq=60 #一定时间内检查文件的修改时间, 这里设置检查的时间周期, 默认为 2, 单位为秒 opcache.fast_shutdown=1 #开启快速停止续发事件，依赖于Zend引擎的内存管理模块，一次释放全部请求变量的内存，而不是依次释放内存块 opcache.enable_file_override=1 #启用检查 PHP 脚本存在性和可读性的功能，无论文件是否已经被缓存，都会检查操作码缓存,可以提升性能。 但是如果禁用了 opcache.validate_timestamps选项， 可能存在返回过时数据的风险。 比较知名的是XCache、Turck MM Cache、PHP Accelerator等。 "},"php/base/base-4.html":{"url":"php/base/base-4.html","title":"2.1.4 PHP编码规范","keywords":"","body":"PHP编码规范 目前官方已制定的规范包括以下六份文件： PSR-0 (已弃用) PSR-1 PSR-2 PSR-2补充 PSR-3 PSR-4 2014/04/25 添加PSR-2补充文件以及修改之前版本中的翻译不当与错误。 2014/07/31 添加PSR-4。 PSR-1 基本代码规范 本篇规范制定了代码基本元素的相关标准， 以确保共享的PHP代码间具有较高程度的技术互通性。 1. 概览 PHP代码文件必须以 PHP代码文件必须以 不带BOM的 UTF-8 编码； PHP代码中应该只定义类、函数、常量等声明，或其他会产生 从属效应 的操作（如：生成文件输出以及修改.ini配置文件等），二者只能选其一； 命名空间以及类必须符合 PSR 的自动加载规范：PSR-0 或 PSR-4 中的一个； 类的命名必须遵循 StudlyCaps 大写开头的驼峰命名规范； 类中的常量所有字母都必须大写，单词间用下划线分隔； 方法名称必须符合 camelCase 式的小写开头驼峰命名规范。 2. 文件 2.1. PHP标签 PHP代码必须使用 长标签 或 短输出标签； 一定不可使用其它自定义标签。 2.2. 字符编码 PHP代码必须且只可使用不带BOM的UTF-8编码。 2.3. 从属效应（副作用） 一份PHP文件中应该要不就只定义新的声明，如类、函数或常量等不产生从属效应的操作，要不就只有会产生从属效应的逻辑操作，但不该同时具有两者。 “从属效应”(side effects)一词的意思是，仅仅通过包含文件，不直接声明类、 函数和常量等，而执行的逻辑操作。 “从属效应”包含却不仅限于：生成输出、直接的 require 或 include、连接外部服务、修改 ini 配置、抛出错误或异常、修改全局或静态变量、读或写文件等。 以下是一个反例，一份包含声明以及产生从属效应的代码： \\n\"; // 声明函数 functionfoo(){ // 函数主体部分 } 下面是一个范例，一份只包含声明不产生从属效应的代码： 3. 命名空间和类 命名空间以及类的命名必须遵循 PSR-0. 根据规范，每个类都独立为一个文件，且命名空间至少有一个层次：顶级的组织名称（vendor name）。 类的命名必须 遵循 StudlyCaps 大写开头的驼峰命名规范。 PHP 5.3及以后版本的代码必须使用正式的命名空间。 例如： 5.2.x及之前的版本应该使用伪命名空间的写法，约定俗成使用顶级的组织名称（vendor name）如 Vendor_ 为类前缀。 4. 类的常量、属性和方法 此处的“类”指代所有的类、接口以及可复用代码块（traits） 4.1. 常量 类的常量中所有字母都必须大写，词间以下划线分隔。 参照以下代码： 4.2. 属性 类的属性命名可以遵循 大写开头的驼峰式 ($StudlyCaps)、小写开头的驼峰式 ($camelCase) 又或者是 下划线分隔式 ($under_score)，本规范不做强制要求，但无论遵循哪种命名方式，都应该在一定的范围内保持一致。这个范围可以是整个团队、整个包、整个类或整个方法。 4.3. 方法 方法名称必须符合 camelCase() 式的小写开头驼峰命名规范。 PSR-2 代码风格规范 本篇规范是 PSR-1 基本代码规范的继承与扩展。 本规范希望通过制定一系列规范化PHP代码的规则，以减少在浏览不同作者的代码时，因代码风格的不同而造成不便。 当多名程序员在多个项目中合作时，就需要一个共同的编码规范， 而本文中的风格规范源自于多个不同项目代码风格的共同特性， 因此，本规范的价值在于我们都遵循这个编码风格，而不是在于它本身。 1. 概览 代码必须遵循 PSR-1 中的编码规范 。 代码必须使用4个空格符而不是 tab键 进行缩进。 每行的字符数应该软性保持在80个之内， 理论上一定不可多于120个， 但一定不能有硬性限制。 每个 namespace 命名空间声明语句和 use 声明语句块后面，必须插入一个空白行。 类的开始花括号({)必须写在函数声明后自成一行，结束花括号(})也必须写在函数主体后自成一行。 方法的开始花括号({)必须写在函数声明后自成一行，结束花括号(})也必须写在函数主体后自成一行。 类的属性和方法必须添加访问修饰符（private、protected 以及 public）， abstract 以及 final必须声明在访问修饰符之前，而 static必须声明在访问修饰符之后。 控制结构的关键字后必须要有一个空格符，而调用方法或函数时则一定不能有。 控制结构的开始花括号({)必须写在声明的同一行，而结束花括号(})必须写在主体后自成一行。 控制结构的开始左括号后和结束右括号前，都一定不能有空格符。 1.1. 例子 以下例子程序简单地展示了以上大部分规范： $b) { $foo->bar($arg1); } else { BazClass::bar($arg2, $arg3); } } final public static functionbar() { // method body } } 2. 通则 2.1 基本编码准则 代码必须符合 PSR-1 中的所有规范。 2.2 文件 所有PHP文件必须使用Unix LF (linefeed)作为行的结束符。 所有PHP文件必须以一个空白行作为结束。 纯PHP代码文件必须省略最后的 ?> 结束标签。 2.3. 行 行的长度一定不能有硬性的约束。 软性的长度约束一定要限制在120个字符以内，若超过此长度，带代码规范检查的编辑器一定要发出警告，不过一定不可发出错误提示。 每行不应该多于80个字符，大于80字符的行应该折成多行。 非空行后一定不能有多余的空格符。 空行可以使得阅读代码更加方便以及有助于代码的分块。 每行一定不能存在多于一条语句。 2.4. 缩进 代码必须使用4个空格符的缩进，一定不能用 tab键 。 备注: 使用空格而不是tab键缩进的好处在于， 避免在比较代码差异、打补丁、重阅代码以及注释时产生混淆。 并且，使用空格缩进，让对齐变得更方便。 2.5. 关键字 以及 True/False/Null PHP所有 关键字必须全部小写。 常量 true 、false 和 null 也必须全部小写。 3. namespace 以及 use 声明 namespace 声明后 必须 插入一个空白行。 所有 use 必须 在 namespace 后声明。 每条 use 声明语句 必须 只有一个 use 关键词。 use 声明语句块后 必须 要有一个空白行。 例如： 4. 类、属性和方法 此处的“类”泛指所有的class类、接口以及traits可复用代码块。 4.1. 扩展与继承 关键词 extends 和 implements必须写在类名称的同一行。 类的开始花括号必须独占一行，结束花括号也必须在类主体后独占一行。 implements 的继承列表也可以分成多行，这样的话，每个继承接口名称都必须分开独立成行，包括第一个。 4.2. 属性 每个属性都必须添加访问修饰符。 一定不可使用关键字 var 声明一个属性。 每条语句一定不可定义超过一个属性。 不要使用下划线作为前缀，来区分属性是 protected 或 private。 以下是属性声明的一个范例： 4.3. 方法 所有方法都必须添加访问修饰符。 不要使用下划线作为前缀，来区分方法是 protected 或 private。 方法名称后一定不能有空格符，其开始花括号必须独占一行，结束花括号也必须在方法主体后单独成一行。参数左括号后和右括号前一定不能有空格。 一个标准的方法声明可参照以下范例，留意其括号、逗号、空格以及花括号的位置。 4.4. 方法的参数 参数列表中，每个参数后面必须要有一个空格，而前面一定不能有空格。 有默认值的参数，必须放到参数列表的末尾。 参数列表可以分列成多行，这样，包括第一个参数在内的每个参数都必须单独成行。 拆分成多行的参数列表后，结束括号以及方法开始花括号 必须 写在同一行，中间用一个空格分隔。 4.5. abstract 、 final 、 以及 static 需要添加 abstract 或 final 声明时， 必须写在访问修饰符前，而 static 则必须写在其后。 4.6. 方法及函数调用 方法及函数调用时，方法名或函数名与参数左括号之间一定不能有空格，参数右括号前也 一定不能有空格。每个参数前一定不能有空格，但其后必须有一个空格。 bar($arg1); Foo::bar($arg2, $arg3); 参数可以分列成多行，此时包括第一个参数在内的每个参数都必须单独成行。 bar( $longArgument, $longerArgument, $muchLongerArgument ); 5. 控制结构 控制结构的基本规范如下： 控制结构关键词后必须有一个空格。 左括号 ( 后一定不能有空格。 右括号 ) 前也一定不能有空格。 右括号 ) 与开始花括号 { 间一定有一个空格。 结构体主体一定要有一次缩进。 结束花括号 }一定在结构体主体后单独成行。 每个结构体的主体都必须被包含在成对的花括号之中， 这能让结构体更加结构话，以及减少加入新行时，出错的可能性。 5.1. if 、 elseif 和 else 标准的 if 结构如下代码所示，留意 括号、空格以及花括号的位置， 注意 else 和 elseif 都与前面的结束花括号在同一行。 应该使用关键词 elseif 代替所有 else if ，以使得所有的控制关键字都像是单独的一个词。 5.2. switch 和 case 标准的 switch 结构如下代码所示，留意括号、空格以及花括号的位置。 case 语句必须相对 switch 进行一次缩进，而 break 语句以及 case 内的其它语句都 必须 相对 case 进行一次缩进。 如果存在非空的 case 直穿语句，主体里必须有类似 // no break 的注释。 5.3. while 和 do while 一个规范的 while 语句应该如下所示，注意其 括号、空格以及花括号的位置。 标准的 do while 语句如下所示，同样的，注意其 括号、空格以及花括号的位置。 5.4. for 标准的 for 语句如下所示，注意其 括号、空格以及花括号的位置。 5.5. foreach 标准的 foreach 语句如下所示，注意其 括号、空格以及花括号的位置。 $value) { // foreach body } 5.6. try, catch 标准的 try catch 语句如下所示，注意其 括号、空格以及花括号的位置。 6. 闭包 闭包声明时，关键词 function 后以及关键词 use 的前后都必须要有一个空格。 开始花括号必须写在声明的同一行，结束花括号必须紧跟主体结束的下一行。 参数列表和变量列表的左括号后以及右括号前，必须不能有空格。 参数和变量列表中，逗号前必须不能有空格，而逗号后必须要有空格。 闭包中有默认值的参数必须放到列表的后面。 标准的闭包声明语句如下所示，注意其 括号、逗号、空格以及花括号的位置。 参数列表以及变量列表可以分成多行，这样，包括第一个在内的每个参数或变量都必须单独成行，而列表的右括号与闭包的开始花括号必须放在同一行。 以下几个例子，包含了参数和变量列表被分成多行的多情况。 注意，闭包被直接用作函数或方法调用的参数时，以上规则仍然适用。 bar( $arg1, function($arg2)use($var1){ // body }, $arg3 ); 7. 总结 以上规范难免有疏忽，其中包括但不仅限于： 全局变量和常量的定义 函数的定义 操作符和赋值 行内对齐 注释和文档描述块 类名的前缀及后缀 最佳实践 本规范之后的修订与扩展将弥补以上不足。 PSR-3 日志接口规范 PSR-4 自动载入 "},"php/ext.html":{"url":"php/ext.html","title":"2.2 扩展库","keywords":"","body":"空着，待写…… "},"php/example.html":{"url":"php/example.html","title":"2.3 实战案例","keywords":"","body":""},"php/example/example-1.html":{"url":"php/example/example-1.html","title":"2.3.1 composer用法","keywords":"","body":"1.3.1 composer用法 1、将github仓库代码down到本地 方法一 echo \"# ccc\" >> README.md git init git add README.md git commit -m \"first commit\" git remote add origin https://github.com/liaozongchao/ccc.git git push -u origin master 方法二 git remote add origin https://github.com/liaozongchao/ccc.git git push -u origin master 2、初始化包 composer init 结果大概如下(composer.json)： { \"name\": \"liao/liming\", \"description\": \"liming\", \"license\": \"Apache-2.0\", \"keywords\": [\"liao\", \"sdk\"], \"homepage\": \"https://github.com/liaozongchao/bbb\", \"type\": \"library\", \"authors\": [ { \"name\": \"liaozongchao\", \"email\": \"liaozongchao@yiihua.com\" } ], \"require\": {}, \"autoload\": { \"files\": [ \"src/app/functions.php\" ], \"psr-4\": { \"App\\\\\": \"src/app\" } } } 注明： files:直接引用文件 psr-4 : 按照psr-4标准引用类文件 代码格式 3、将代码推送到github上 git add README.md git commit -m \"first commit\" git push -u origin master 注意：修改.git/config（url = https://liaozongchao@github.com/liaozongchao/ccc.git） 4、登录到https://packagist.org/packages/submit 网站操作 提交：https://github.com/liaozongchao/ccc 总结：以上操作即可成功，安装库： composer require liao/liming:dev-master "},"php/example/example-2.html":{"url":"php/example/example-2.html","title":"2.3.2 魔术方法","keywords":"","body":"PHP之十六个魔术方法详解 __construct()，类的构造函数 __destruct()，类的析构函数 __call()，在对象中调用一个不可访问方法时调用 __callStatic()，用静态方式中调用一个不可访问方法时调用 __get()，获得一个类的成员变量时调用 __set()，设置一个类的成员变量时调用 __isset()，当对不可访问属性调用isset()或empty()时调用 __unset()，当对不可访问属性调用unset()时被调用。 __sleep()，执行serialize()时，先会调用这个函数 __wakeup()，执行unserialize()时，先会调用这个函数 __toString()，类被当成字符串时的回应方法 __invoke()，调用函数的方式调用一个对象时的回应方法 __set_state()，调用var_export()导出类时，此静态方法会被调用。 __clone()，当对象复制完成时调用 __autoload()，尝试加载未定义的类 __debugInfo()，打印所需调试信息 举例：1、__debugInfo() ，打印所需调试信息 prop = $val; } /** * @return array */ public function __debugInfo() { return [ 'propSquared' => $this->prop ** 2, ]; } } var_dump(new C(42)); 2、__clone()，当对象复制完成时调用 name = $name; $this->age = $age; $this->sex = $sex; } public function __clone() { echo __METHOD__.\"你正在克隆对象\"; } } $person = new Person('小明'); // 初始赋值 $person2 = clone $person; "},"php/example/example-3.html":{"url":"php/example/example-3.html","title":"2.3.3 链表算法","keywords":"","body":"1.3.3 链表算法 "},"php/example/example-4.html":{"url":"php/example/example-4.html","title":"2.3.4 算法案例","keywords":"","body":"1.3.4 算法案例 "},"php/algorithm.html":{"url":"php/algorithm.html","title":"2.4 算法案例","keywords":"","body":"空着，待写…… "},"php/algorithm/algorithm-1.html":{"url":"php/algorithm/algorithm-1.html","title":"2.4.1 PHP的LRU实现","keywords":"","body":"LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 class Node { private $key; private $val; private $previous; private $next; public function __construct($key, $val) { $this->key = $key; $this->val = $val; } public function setVal($val) { $this->val = $val; } public function getKey() { return $this->key; } public function getVal() { return $this->val; } public function setPrevious($previous) { $this->previous = $previous; } public function getPrevious() { return $this->previous; } public function setNext($next) { $this->next = $next; } public function getNext() { return $this->next; } } class LRU { private $hashmap = array(); private $head; private $tail; private $cacheNum = 0; public function __construct($cacheNum) { $this->cacheNum = $cacheNum; $this->hashmap = array(); $this->head = new Node(null, null); $this->tail = new Node(null, null); $this->head->setNext($this->tail); $this->tail->setPrevious($this->head); } public function get($key) { if (!isset($this->hashmap[$key])) { return null; } $node = $this->hashmap[$key]; if (count($this->hashmap) == 1) { return $node->getVal(); } //处理链表 return $node->getVal(); } public function put($key, $val) { if ($this->cacheNum hashmap[$key]) && !empty($this->hashmap[$key])) { //更新数据 $node = $this->hashmap[$key]; $this->detach($node); $this->attach($this->head, $node); $node->setVal($val); } else { $node = new Node($key, $val); $this->hashmap[$key] = $node; //处理数据 $this->attach($this->head, $node); if (count($this->hashmap) > $this->cacheNum) { $nodeRemove = $this->tail->getPrevious(); $this->detach($nodeRemove); unset($this->hashmap[$nodeRemove->getKey()]); } } return true; } private function attach($head, $node) { $node->setPrevious($head); $node->setNext($head->getNext()); $node->getNext()->setPrevious($node); $node->getPrevious()->setNext($node); } private function detach($node) { $node->getPrevious()->setNext($node->getNext()); $node->getNext()->setPrevious($node->getPrevious()); } } error_reporting(0); echo '开始内存：'.round(memory_get_usage()/1024/1024, 2).\"\\n\"; $numEntries = 100000; $lru = new LRU($numEntries); while ($numEntries > 0) { $lru->put($numEntries - 99999, 'some value...' . $numEntries); $numEntries--; } echo '运行后内存：'.round(memory_get_usage()/1024/1024, 2).\"\\n\"; "},"php/algorithm/algorithm-2.html":{"url":"php/algorithm/algorithm-2.html","title":"2.4.2 排序算法","keywords":"","body":"1. 冒泡排序 冒泡排序算法的原理如下： 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 $arr[$j+1]) { $temp = $arr[$j+1]; $arr[$j+1] = $arr[$j]; $arr[$j] = $temp; } } } return $arr; } $arr = [18,29,37,13,9,19]; $res = bubbling($arr); print_r($res); ?> 2. 选择排序 选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理是每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到全部待排序的数据元素排完。 选择排序是不稳定的排序方法。 function select($arr) { $num = count($arr); for ($i = 0; $i $arr[$j]) { $min = $j; } } if ($min != $i) { $temp = $arr[$min]; $arr[$min] = $arr[$i]; $arr[$i] = $temp; } } return $arr; } $arr = [18, 29, 37, 13, 9, 19]; $res = select($arr); print_r($res); 3. 插入排序 插入排序（Insertion sort）是一种简单直观且稳定的排序算法。如果有一个已经有序的数据序列，要求在这个已经排好的数据序列中插入一个数，但要求插入后此数据序列仍然有序，这个时候就要用到一种新的排序方法——插入排序法,插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序，时间复杂度为O(n^2)。是稳定的排序方法。 function insert($arr) { $num = count($arr); for ($i=1; $i 0 && $arr[$j-1] > $temp) { $arr[$j] = $arr[$j-1]; $j--; } // for ($j; $j > 0; $j--) { // if ($arr[$j - 1] > $temp) { // $arr[$j] = $arr[$j - 1]; // }else{ // break; // } // } $arr[$j] = $temp; } return $arr; } $arr = [18, 29, 37, 13, 9, 19]; $res = insert($arr); print_r($res); "},"php/algorithm/algorithm-3.html":{"url":"php/algorithm/algorithm-3.html","title":"2.4.3 链表算法","keywords":"","body":"数据结构与算法之PHP实现链表类（单链表/双链表/循环链表）链表是由一组节点组成的集合。每个节点都使用一个对象的引用指向它的后继。指向另一个节点的引用叫做链。链表分为单链表、双链表、循环链表。 1. 单向链表 插入：链表中插入一个节点的效率很高。向链表中插入一个节点，需要修改它前面的节点(前驱)，使其指向新加入的节点，而新加入的节点则指向原来前驱指向的节点（见下图）。 由上图可知，B、C之间插入D，三者之间的关系为 current为插入节点的前驱节点 current->next = new // B节点指向新节点Dnew->next = current->next // 新节点D指向B的后继节点C删除：从链表中删除一个元素，将待删除元素的前驱节点指向待删除元素的后继节点，同时将待删除元素指向 null，元素就删除成功了（见下图）。 由上图可知，A、C之间删除B，三者之间的关系为 current为要删除节点的前驱节点current->next = current->next->next // A节点指向C节点 data = $data; } public function setNext($next) { $this->next = $next; } public function getNext() { return $this->next; } } class Links { private $header; public function __construct($data) { $this->header = new Node($data); //$this->header->setNext($this->header); 加上这句话为循环列表 } public function find($data) { $current = $this->header; while ($current->data != $data) { $current = $current->getNext(); } return $current; } public function put($header, $data) { $node = new Node($data); $current = $this->find($header); if ($current->data && $current->getNext() != $this->header) { $node->setNext($current->getNext()); $current->setNext($node); } else { $current->setNext($node); $node->setNext($this->header); } } public function del($data) { $current = $this->header; while ($current->getNext()->data != $data) { $current = $current->getNext(); } if ($current->getNext() != $this->header) { // 链表中间 $current->setNext($current->getNext()->getNext()); } else { // 链表尾端 $current->setNext($this->header); } } } $ln = new Links(''); // print_r($ln); $ln->put('', 'two'); // print_r($ln); $ln->put('two', 'three'); // print_r($ln); $ln->put('three', 'four'); // print_r($ln); // exit; $ln->del('three'); print_r($ln); 2. 双向链表 单链表从链表的头节点遍历到尾节点很简单，但从后向前遍历就没那么简单了。它的每个数据结点中都有两个指针，分别指向直接后继和直接前驱。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点。 插入：插入一个节点时，需要指出该节点正确的前驱和后继。修改待插入节点的前驱节点的next属性，使其指向新加入的节点，而新插入的节点的next属性则指向原来前驱指向的节点，同时将原来前驱指向的节点的previous属性指向新节点，而新加入节点的previous属性指向它前驱节点（见下图）。 由上图可知，B、C之间插入D，三者之间的关系为current为插入节点的前驱节点current->next = new // B的next属性指向新节点Dnew->next = current->next // 新节点D的next属性指向B的后继节点Ccurrent->next->previous = new // B的后继节点C的previous属性指向新节点D（原先是C的previous属性指向B）删除：双向链表的删除操作比单向链表的效率更高，因为不需要再查找前驱节点了。首先需要在链表中找出存储待删除数据的节点，然后设置该节点前驱的 next 属性，使其指向待删除节点的后继;设置该节点后继的 previous 属性，使其指向待删除节点的前驱。 由上图可知，B、C之间删除D，三者之间的关系为current为要删除的节点current->previous->next = current->next // B的前驱节点A的next属性指向B的后继节点Ccurrent->next->previous = current->previous // B的后继节点C的previous属性指向B的前驱节点Acurrent->previous = null // B的previous属性指向nullcurrent->next = null // B的next属性指向null data = $data; } public function setNext($next) { $this->next = $next; } public function getNext() { return $this->next; } } class Links { private $header; public function __construct($data) { $this->header = new Node($data); $this->header->setNext($this->header); } public function find($data) { $current = $this->header; while ($current->data != $data) { $current = $current->getNext(); } return $current; } public function put($header, $data) { $node = new Node($data); $current = $this->find($header); if ($current->data && $current->getNext() != $this->header) { $node->setNext($current->getNext()); $current->setNext($node); } else { $current->setNext($node); $node->setNext($this->header); } } public function del($data) { $current = $this->header; while ($current->getNext()->data != $data) { $current = $current->getNext(); } if ($current->getNext() != $this->header) { // 链表中间 $current->setNext($current->getNext()->getNext()); } else { // 链表尾端 $current->setNext($this->header); } } } $ln = new Links(''); // print_r($ln); $ln->put('', 'two'); // print_r($ln); $ln->put('two', 'three'); // print_r($ln); $ln->put('three', 'four'); // print_r($ln); // exit; $ln->del('three'); print_r($ln); "},"php/algorithm/algorithm-4.html":{"url":"php/algorithm/algorithm-4.html","title":"2.4.4 算法实践","keywords":"","body":"算法实践 1. PHP实现从1累加到100(1+2+….+100=)的几种思路? function sum1($num) { if ($num > 0) { return $num + sum1($num - 1); } } $a = sum1(100); echo $a; function sum2($num) { $sum = 0; for ($i = 1; $i 0) { $sum += $num; $num--; } return $sum; } $a = sum3(100); echo $a; echo array_sum(range(1, 100)); 2. PHP 链式操作 class DB { public function __construct() { } public function select() { return $this; } public function where() { return $this; } public function limit() { return $this; } public function orderBy() { return $this; } } $db = new DB(); $db->select()->where()->limit()->orderBy(); 3. 斐波那契数列 递归 function recursive($n) { if($n == 0 || $n == 1) return $n; return sum($n-1) + sum($n-2); } 迭代 function iteration($n) { $n0 = 0; $n1 = 1; $res = 0; for ($i = 2; $i 4. 两数相加 给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。 输入：(2 -> 4 -> 3) + (5 -> 6 -> 4) 输出：7 -> 0 -> 8 class ListNode { public $val = 0; public $next = null; function __construct($val) { $this->val = $val; } } class Solution { /** * @param ListNode $l1 * @param ListNode $l2 * @return ListNode */ public function addTwoNumbers($l1, $l2) { $current = null; $num = 0; do{ $val = $l1->val + $l2->val + $num; if($val = 10){ $val -= 10;$num = 1;} $node = new ListNode($val); if($current) { $next->next= $node; }else{ $current = $node; } $next = $node; $l1 = $l1->next; $l2 = $l2->next; }while ($l1 || $l2 || $num); return $current; } } "},"php/design.html":{"url":"php/design.html","title":"2.5 设计模式","keywords":"","body":"空着，待写…… "},"php/design/design-1.html":{"url":"php/design/design-1.html","title":"2.5.1 工厂模式","keywords":"","body":"在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 "},"php/design/design-2.html":{"url":"php/design/design-2.html","title":"2.5.2 单例模式","keywords":"","body":" 单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 "},"php/design/design-3.html":{"url":"php/design/design-3.html","title":"2.5.3 注册树模式","keywords":"","body":"将对象注册到一个类中通过该类实现全局访问操作对象 $user = new \\Lib\\User($id); Register::set($key,$user); "},"php/design/design-4.html":{"url":"php/design/design-4.html","title":"2.5.4 适配器模式","keywords":"","body":"适配器模式:即将截然不同的函数接口封装成统一的接口API例如 MYSQL的数据库扩展操作 mysql,mysqli,pdo三种,可以用适配器模式统一成一致.类似的场景还有cache操作,例如 redis,memcached,mongodb,apc等不同的缓存函数,统一成一致 conn = mysqli_connect($host,$user,$pass,$db); } public function query($sql) { return mysqli_query($this->conn ,$sql); } public function close() { mysqli_close($this->conn); } } $db = new \\Lib\\Database\\Mysqli(); print_r($db); "},"php/design/design-5.html":{"url":"php/design/design-5.html","title":"2.5.5 策略模式","keywords":"","body":"将一组特定的行为和算法封装成类,以适应某些特定的上下文环境.这种模式就是策略模式. strategy = $userStrategy; } public function action() { $this->strategy->showCategory(); } } $page = new \\Lib\\Page(); //根绝条件执行 $page->setContext(new \\Lib\\WomanStrategy()); $page->action(); "},"php/design/design-6.html":{"url":"php/design/design-6.html","title":"2.5.6 数据对象映射模式","keywords":"","body":"是将对象和数据存储映射起来，对一个对象的操作会映射为对数据存储的操作。例如在代码中 new 一个对象，使用数据对象映射模式就可以将对象的一些操作比如设置一些属性，就会自动保存到数据库，跟数据库中表的一条记录对应起来。 db = Factory::getDb(); $this->db->connect('127.0.0.1','root',123456,'demo'); $result = $this->db->query(\"select * from user where id = $id\"); $row = $result->fetch_assoc(); $this->id = $row['id']; $this->name = $row['name']; $this->email = $row['email']; $this->addtime = $row['addtime']; } public function __destruct() { $this->db->query(\"update user set name = '{$this->name}',email = '{$this->email}',addtime = '{$this->addtime}' where id = '{$this->id}'\"); } } public static function getUser($id) { $key = 'user'.$id; $user = Register::get($key); if(!$user) { $user = new \\Lib\\User($id); Register::set($key,$user); } return $user; } $user = \\Lib\\Factory::getUser(1); print_r($user); "},"php/design/design-7.html":{"url":"php/design/design-7.html","title":"2.5.7 观察者模式","keywords":"","body":"观察者模式(Observer),当一个对象的状态发生改变时，依赖他的对象会全部收到通知，并自动更新。场景:一个事件发生后,要执行一连串更新操作.传统的编程方式,就是在事件的代码之后直接加入处理逻辑,当更新得逻辑增多之后,代码会变得难以维护.这种方式是耦合的,侵入式的,增加新的逻辑需要改变事件主题的代码观察者模式实现了低耦合,非侵入式的通知与更新机制 observers[] = $observer; } public function notify() { if($this->observers) { foreach ($this->observers as $k=>$v) { $v->update(); } } } } notify(); } } $event = new \\Test\\Event(); $event->attach(new \\Test\\observer1()); $event->attach(new \\Test\\observer2()); $event->trigger(); "},"php/design/design-8.html":{"url":"php/design/design-8.html","title":"2.5.8 原型模式","keywords":"","body":"原型模式就是clone就是内存拷贝，比new的好处是创建对象快速，适合大对象创建 1.原型模式与工厂模式作用类似,都是用来创建对象2.与工厂模式的实现不同,原型模式是先创建好一个原型对象,然后通过clone原型对象来创建新的对象,这3.原型模式适用于大对象的创建,创建一个大对象需要很大的开销,如果每次new就会消耗很大,原型模式仅需内存拷贝即可 $pro = new \\Lib\\ConcretePrototype(); $pro->name = 'liaozongchao'; $pro->age = 25; print_r($pro); $proCopy = $pro->shallowCopy(); $proCopy->age = 26; print_r($proCopy); print_r($pro); "},"php/design/design-9.html":{"url":"php/design/design-9.html","title":"2.5.9 装饰器模式","keywords":"","body":"1.装饰器模式（Decorator），可以动态地添加修改类的功能2.一个类提供了一项功能，如果要在修改并添加额外的功能，传统的编程模式，需要写一个子类继承它，并重新实现类的方法3.使用装饰器模式，仅需在运行时添加一个装饰器对象即可实现，可以实现最大的灵活性 beforePencil(); echo \"我是装饰器\"; $this->afterPencil(); } public function addDecorator($decorator) { $this->decorator[] = $decorator; } public function beforePencil() { if($this->decorator) { foreach ($this->decorator as $decorator) { $decorator->before(); } } } public function afterPencil() { if($this->decorator) { $tmp = array_reverse($this->decorator); foreach ($tmp as $decorator) { $decorator->after(); } } } } $draw = new \\Lib\\Draw(); $colorDecorator = new \\Lib\\ColorDecorator(); $draw->addDecorator($colorDecorator); $draw->pencil(); "},"php/design/design-10.html":{"url":"php/design/design-10.html","title":"2.5.10 迭代器模式","keywords":"","body":"迭代器：类继承PHP的Iterator接口，批量操作。 迭代器模式，在不需要了解内部实现的前提下，遍历一个聚合对象的内部元素。 相比传统的编程模式，迭代器模式可以隐藏遍历元素的所需操作。 connect('127.0.0.1','root',123456,'demo'); $result = $db->query(\"select id from user\"); $this->data = $result->fetch_all(MYSQLI_ASSOC); var_dump($this->data); } public function current(){ $id = $this->data[$this->index]['id']; return Factory::getUser($id); } public function next(){ return $this->index++; } public function key(){ return $this->index; } public function valid(){ return $this->index data); } public function rewind(){ $this->index = 0; } } $users = new \\Lib\\AllUser(); foreach ($users as $user){ print_r($user); } "},"php/design/design-11.html":{"url":"php/design/design-11.html","title":"2.5.11 代理模式","keywords":"","body":""},"python/python.html":{"url":"python/python.html","title":"3. Python篇","keywords":"","body":"空着，待写…… "},"python/base.html":{"url":"python/base.html","title":"3.1 基础语法","keywords":"","body":"空着，待写…… "},"python/ext.html":{"url":"python/ext.html","title":"3.2 扩展库","keywords":"","body":"空着，待写…… "},"python/example.html":{"url":"python/example.html","title":"3.3 实战案例","keywords":"","body":"空着，待写…… "},"network/network.html":{"url":"network/network.html","title":"4. 网络篇","keywords":"","body":""},"network/socket.html":{"url":"network/socket.html","title":"4.1 Socket","keywords":"","body":"什么是 socket？ socket 的原意是“插座”，在计算机通信领域，socket 被翻译为“套接字”，它是计算机之间进行通信的一种约定或一种方式。通过 socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据。 socket 的典型应用就是 Web 服务器和浏览器：浏览器获取用户输入的 URL，向服务器发起请求，服务器分析接收到的 URL，将对应的网页内容返回给浏览器，浏览器再经过解析和渲染，就将文字、图片、视频等元素呈现给用户。 UNIX/Linux 中的 socket 是什么？ 在 UNIX/Linux 系统中，为了统一对各种硬件的操作，简化接口，不同的硬件设备也都被看成一个文件。对这些文件的操作，等同于对磁盘上普通文件的操作。 你也许听很多高手说过，UNIX/Linux 中的一切都是文件！那个家伙说的没错。 为了表示和区分已经打开的文件，UNIX/Linux 会给每个文件分配一个 ID，这个 ID 就是一个整数，被称为文件描述符（File Descriptor）。例如：通常用 0 来表示标准输入文件（stdin），它对应的硬件设备就是键盘；通常用 1 来表示标准输出文件（stdout），它对应的硬件设备就是显示器。 UNIX/Linux 程序在执行任何形式的 I/O 操作时，都是在读取或者写入一个文件描述符。一个文件描述符只是一个和打开的文件相关联的整数，它的背后可能是一个硬盘上的普通文件、FIFO、管道、终端、键盘、显示器，甚至是一个网络连接。 请注意，网络连接也是一个文件，它也有文件描述符！你必须理解这句话。 我们可以通过 socket() 函数来创建一个网络连接，或者说打开一个网络文件，socket() 的返回值就是文件描述符。有了文件描述符，我们就可以使用普通的文件操作函数来传输数据了，例如：用 read() 读取从远程计算机传来的数据；用 write() 向远程计算机写入数据。 你看，只要用 socket() 创建了连接，剩下的就是文件操作了，网络编程原来就是如此简单！ WIndow 系统中的 socket 是什么？ Windows 也有类似“文件描述符”的概念，但通常被称为“文件句柄”。因此，本教程如果涉及 Windows 平台将使用“句柄”，如果涉及 Linux 平台则使用“描述符”。 与 UNIX/Linux 不同的是，Windows 会区分 socket 和文件，Windows 就把 socket 当做一个网络连接来对待，因此需要调用专门针对 socket而设计的数据传输函数，针对普通文件的输入输出函数就无效了。 这个世界上有很多种套接字（socket），比如 DARPA Internet 地址（Internet 套接字）、本地节点的路径名（Unix套接字）、CCITT X.25地址（X.25 套接字）等。但本教程只讲第一种套接字——Internet 套接字，它是最具代表性的，也是最经典最常用的。以后我们提及套接字，指的都是 Internet 套接字。 流格式套接字（SOCK_STREAM） SOCK_STREAM 有以下几个特征： 数据在传输过程中不会消失； 数据是按照顺序传输的； 数据的发送和接收不是同步的（有的教程也称“不存在数据边界”）。 数据报格式套接字（SOCK_DGRAM） 可以将 SOCK_DGRAM 比喻成高速移动的摩托车快递，它有以下特征： 强调快速传输而非传输顺序； 传输的数据可能丢失也可能损毁； 限制每次传输的数据大小； 数据的发送和接收是同步的（有的教程也称“存在数据边界”）。 #include #include #include #include #include #include #include int main(){ //创建套接字 int serv_sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); //将套接字和IP、端口绑定 struct sockaddr_in serv_addr; memset(&serv_addr, 0, sizeof(serv_addr)); //每个字节都用0填充 serv_addr.sin_family = AF_INET; //使用IPv4地址 serv_addr.sin_addr.s_addr = inet_addr(\"127.0.0.1\"); //具体的IP地址 serv_addr.sin_port = htons(1234); //端口 bind(serv_sock, (struct sockaddr*)&serv_addr, sizeof(serv_addr)); //进入监听状态，等待用户发起请求 listen(serv_sock, 20); //接收客户端请求 struct sockaddr_in clnt_addr; socklen_t clnt_addr_size = sizeof(clnt_addr); int clnt_sock = accept(serv_sock, (struct sockaddr*)&clnt_addr, &clnt_addr_size); //向客户端发送数据 char str[] = \"http://c.biancheng.net/socket/\"; write(clnt_sock, str, sizeof(str)); //关闭套接字 close(clnt_sock); close(serv_sock); return 0; } #include #include #include #include #include #include int main(){ //创建套接字 int sock = socket(AF_INET, SOCK_STREAM, 0); //向服务器（特定的IP和端口）发起请求 struct sockaddr_in serv_addr; memset(&serv_addr, 0, sizeof(serv_addr)); //每个字节都用0填充 serv_addr.sin_family = AF_INET; //使用IPv4地址 serv_addr.sin_addr.s_addr = inet_addr(\"127.0.0.1\"); //具体的IP地址 serv_addr.sin_port = htons(1234); //端口 connect(sock, (struct sockaddr*)&serv_addr, sizeof(serv_addr)); //读取服务器传回的数据 char buffer[40]; read(sock, buffer, sizeof(buffer)-1); printf(\"Message form server: %s\\n\", buffer); //关闭套接字 close(sock); return 0; } socket缓冲区 每个 socket 被创建后，都会分配两个缓冲区，输入缓冲区和输出缓冲区。 write()/send() 并不立即向网络中传输数据，而是先将数据写入缓冲区中，再由TCP协议将数据从缓冲区发送到目标机器。一旦将数据写入到缓冲区，函数就可以成功返回，不管它们有没有到达目标机器，也不管它们何时被发送到网络，这些都是TCP协议负责的事情。 TCP协议独立于 write()/send() 函数，数据有可能刚被写入缓冲区就发送到网络，也可能在缓冲区中不断积压，多次写入的数据被一次性发送到网络，这取决于当时的网络情况、当前线程是否空闲等诸多因素，不由程序员控制。 read()/recv() 函数也是如此，也从输入缓冲区中读取数据，而不是直接从网络中读取。 TCP套接字的I/O缓冲区示意图 图：TCP套接字的I/O缓冲区示意图 这些I/O缓冲区特性可整理如下： I/O缓冲区在每个TCP套接字中单独存在； I/O缓冲区在创建套接字时自动生成； 即使关闭套接字也会继续传送输出缓冲区中遗留的数据； 关闭套接字将丢失输入缓冲区中的数据。 "},"network/docker.html":{"url":"network/docker.html","title":"4.2 Docker","keywords":"","body":"1.1 docker 1.1什么是 Docker Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 2 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 AUFS 类的 Union FS 等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 下面的图片比较了 Docker 和传统虚拟化方式的不同之处。传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 图 1.4.1.1 - 传统虚拟化 图 1.4.1.2 - Docker 1.2使用 Docker 镜像 在之前的介绍中，我们知道镜像是 Docker 的三大组件之一。 Docker 运行容器前需要本地存在对应的镜像，如果本地不存在该镜像，Docker 会从镜像仓库下载该镜像。 本章将介绍更多关于镜像的内容，包括： 1.21 从仓库获取镜像 docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] docker pull ubuntu:18.04 1.22 管理本地主机上的镜像； 列出镜像docker image ls //列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。 docker image ls -a docker image ls ubuntu docker system df //查看镜像、容器、数据卷所占用的空间。 删除本地镜像 docker image rm [选项] [ ...] docker image rm 501 docker image rm centos docker image rm $(docker image ls -q redis) //删除所有仓库名为 redis 的镜像 docker image rm $(docker image ls -q -f before=mongo:3.2) //删除所有在 mongo:3.2 之前的镜像 1.3 操作 Docker 容器 容器是 Docker 又一核心概念。 简单的说，容器是独立运行的一个或一组应用，以及它们的运行态环境。对应的，虚拟机可以理解为模拟运行的一整套操作系统（提供了运行态环境和其他系统环境）和跑在上面的应用。 本章将具体介绍如何来管理一个容器，包括创建、启动和停止等。 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 docker container ls docker container ls -a 介绍镜像实现的基本原理。 1.31 启动 docker run docker run ubuntu:18.04 /bin/echo 'Hello world' //输出一个 “Hello World”，之后终止容器。 docker run -t -i ubuntu:18.04 /bin/bash //启动一个 bash docker container start //直接将一个已经终止的容器启动运行。 docker container logs -d 守护进程 1.32 终止容器 docker container stop [name|id] 1.33 进入容器 在使用 -d 参数时，容器启动后会进入后台。 某些时候需要进入容器进行操作，包括使用 docker attach 命令或 docker exec 命令，推荐大家使用 docker exec 命令，原因会在下面说明。 docker attach 243c docker exec -it webserver bash 1.34 导出和导入 如果要导出本地某个容器，可以使用 docker export 命令。 docker container ls -a docker export 7691a814370e > ubuntu.tar 可以使用 docker import 从容器快照文件中再导入为镜像，例如 cat ubuntu.tar | docker import - test/ubuntu:v1.0 docker image ls docker import http://example.com/exampleimage.tgz example/imagerepo 1.35 删除 docker container rm trusting_newton 1.4 访问仓库 仓库（Repository）是集中存放镜像的地方。 一个容易混淆的概念是注册服务器（Registry）。实际上注册服务器是管理仓库的具体服务器，每个服务器上可以有多个仓库，而每个仓库下面有多个镜像。从这方面来说，仓库可以被认为是一个具体的项目或目录。例如对于仓库地址 dl.dockerpool.com/ubuntu 来说，dl.dockerpool.com 是注册服务器地址，ubuntu 是仓库名。 1.41 Docker Hub Docker 官方维护了一个公共仓库 Docker Hub：https://hub.docker.com docker search centos docker pull centos docker tag ubuntu:18.04 username/ubuntu:18.04 //标记镜像，将ubuntu:18.04标记为username/ubuntu:18.04 1.42 私有仓库 有时候使用 Docker Hub 这样的公共仓库可能不方便，用户可以创建一个本地仓库供私人使用。 本节介绍如何使用本地仓库。 docker-registry 是官方提供的工具，可以用于构建私有的镜像仓库。本文内容基于 docker-registry v2.x 版本。 docker pull registry docker run -d -p 5000:5000 -v /data/registry:/var/lib/registry registry docker tag ubuntu:latest 127.0.0.1:5000/ubuntu:latest docker push 127.0.0.1:5000/ubuntu:latest docker pull 127.0.0.1:5000/ubuntu:latest "},"network/nginx.html":{"url":"network/nginx.html","title":"4.2 nginx负载均衡","keywords":"","body":"nginx负载均衡 nginx负载均衡的5种策略 负载均衡的几种常用方式 1、轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 upstream backserver { server 192.168.0.14; server 192.168.0.15; } 2、weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的 情况。 upstream backserver { server 192.168.0.14 weight=3; server 192.168.0.15 weight=7; } 权重越高，在被访问的概率越大，如上例，分别是30%，70%。 3、ip_hash 上述方式存在一个问题就是说，在负载均衡系统中，假如用户在某台服务器上登录了，那么该用户第二次请求的时候，因为我们是负载均衡系统，每次请求都会重新定位到服务器集群中的某一个，那么已经登录某一个服务器的用户再重新定位到另一个服务器，其登录信息将会丢失，这样显然是不妥的。 我们可以采用ip_hash指令解决这个问题，如果客户已经访问了某个服务器，当用户再次访问时，会将该请求通过哈希算法，自动定位到该服务器。 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 upstream backserver { ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; } 4、fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream backserver { server server1; server server2; fair; } 5、url_hash（第三方） 按访问url的hash结果来分配请求，使每个url定向到同一个（对应的）后端服务器，后端服务器为缓存时比较有效。 upstream backserver { server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32; } 在需要使用负载均衡的server中增加 proxy_pass http://backserver/; upstream backserver{ ip_hash; server 127.0.0.1:9090 down; (down 表示单前的server暂时不参与负载) server 127.0.0.1:8080 weight=2; (weight 默认为1.weight越大，负载的权重就越大) server 127.0.0.1:6060; server 127.0.0.1:7070 backup; (其它所有的非backup机器down或者忙的时候，请求backup机器) } max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误 fail_timeout:max_fails次失败后，暂停的时间 配置实例： #user nobody; worker_processes 4; events { # 最大并发数 worker_connections 1024; } http{ # 待选服务器列表 upstream myproject{ # ip_hash指令，将同一用户引入同一服务器。 ip_hash; server 125.219.42.4 fail_timeout=60s; server 172.31.2.183; } server{ # 监听端口 listen 80; # 根目录下 location / { # 选择哪个服务器列表 proxy_pass http://myproject; } } } 针对负载均衡集群中的session解决方案的总结 在日常运维工作中，当给Web站点使用负载均衡之后，必须面临的一个重要问题就是Session的处理办法，无论是PHP、Python、Ruby还是Java语言环境，只要使用服务器保存Session，在做负载均衡时都需要考虑Session的问题。 通常面临的问题 从用户端来解释，就是当一个用户第一次访问被负载均衡代理到后端服务器A并登录后，服务器A上保留了用户的登录信息；当用户再次发送请求时， 根据负载均衡策略可能被代理到后端不同的服务器，例如服务器B，由于这台服务器B没有用户的登录信息，所以导致用户需要重新登录。这对用户 来说是不可忍受的。所以，在实施负载均衡的时候，我们必须考虑Session的问题。 在负载均衡中，针对Session的处理，一般有以下几种方法： 1）Session会话保持（案例：Nginx、Haproxy） 2）Session会话复制（案例：Tomcat） 3）Session会话共享（案例：Memcached、Redis） 1、Session会话保持 对于Nginx可以选用Session保持的方法实行负载均衡，nginx的upstream目前支持5种方式的分配方式，其中有两种比较通用的Session解决方法，ip_hash和url_hash。 注意：后者不是官方模块，需要额外安装。 会话保持的缺点： 1) 会话保持看似解决了Session同步的问题，但是却带来的一些其它方面的问题： 2）负载不均衡了：由于使用了Session保持，很显然就无法保证负载绝对的均衡。 3）没有彻底解决问题：如果后端有服务器宕机，那么这台服务器的Session丢失，被分配到这台服务请求的用户还是需要重新登录。 2、Session会话保持 既然，我们的目标是所有服务器上都要保持用户的Session，那么将每个应用服务器中的Session信息复制到其它服务器节点上是不是就可以呢？ 这就是Session的第二中处理办法：会话复制。 会话复制在Tomcat上得到了支持，它是基于IP组播（multicast）来完成Session的复制，Tomcat的会话复制分为两种： 1）全局会话复制：利用Delta Manager复制会话中的变更信息到集群中的所有其他节点。 2）非全局复制：使用Backup Manager进行复制，它会把Session复制给一个指定的备份节点。 不过，这里不准备来解释会话复制的Tomcat配置，如果有需求可以参考Tomcat官方文档，主要是因为会话复制不适合大的集群。根据生产的实践案例， 在集群超过6个节点之后就会出现各种问题，不推荐生产使用。 3、Session会话共享 既然会话保持和会话复制都不完美，那么我们为什么不把Session放在一个统一的地方呢，这样集群中的所有节点都在一个地方进行Session的存取就可以解决问题。 Session存放到哪里？ 对于Session来说，肯定是频繁使用的，虽然你可以把它存放在数据库中，但是真正生产环境中我更推荐存放在性能更快的分布式KV数据中， 例如：Memcached和Redis。 PHP设置Session共享 如果使用的是PHP那么恭喜你，配置非常的简单。PHP通过两行配置就可以把Session存放在Memcached或者Redis中，当然你要提前配置好他们。修改php.ini： 使用Memcache存储Session session.save_handler = memcache session.save_path = \"tcp://192.168.56.11:11211\" 使用Redis存储Session session.save_handler = redis session.save_path =\"tcp://localhost:6379\" 提醒：别忘了给PHP安装memcache或者redis插件。 使用缓存保持Session 对于简单的缓存会话： 可以设置SESSION_ENGINE 为”django.contrib.sessions.backends.cache”。此时会话数据将直接存储在你的缓存中。然而，缓存数据将可能不会持久： 如果缓存填满或者缓存服务器重启，缓存数据可能会被清理掉。 若要持久的缓存数据： 可以设置SESSION_ENGINE为”django.contrib.sessions.backends.cached_db”。它的写操作使用缓存，对缓存的每次写入都将再写入到数据库。对于 读取的会话，如果数据不在缓存中，则从数据库读取。两种会话的存储都非常快，但是简单的缓存更快，因为它放弃了持久性。大部分情况下，cached_db后端已经足够快，但是如果你需要榨干最后一点的性能，并且接受会话数据丢失的风险，那么你可使用cache而不是cached_db 使用文件保存Session 使用文件保存Session不再我们的讨论之类，因为很难进行共享，PHP默认也是将Session存放在/tmp目录下。 4、简单总结： 会话保持的缺点：负载不均衡;没有彻底解决问题. 会话复制的缺点：集群超过6个节点就会出现一系列的问题. 会话共享：会话数据共享在Nosql（Redis）数据库中分享。 配置： access_log /data/log/yongle.com.log; error_log /data/log/yongle.com.error; upstream yongle.com { server 127.0.0.1:8081; server 127.0.0.1:8082; server 127.0.0.1:8083; server 127.0.0.1:8084; server 127.0.0.1:8085; } server { listen 80; server_name yongle.com; location / { proxy_pass http://yongle.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } server { listen 8085; server_name yongle.com; root /data/wwwroot/aaa/; location / { index index.html index.htm; } } "},"common/preface.html":{"url":"common/preface.html","title":"尾声","keywords":"","body":"有些情，只能止于唇齿，掩于岁月 卷首引：从此天涯陌路，天各一方。 从此互不来往，斩断情愫。 删除了记忆，清空了珍藏。 不再徘徊在彷徨的路上。 不再泪水央央度过夜的漫长。 崭新的一天湛蓝， 轻装上阵的舒畅。 风送来你的剪影， 搅乱了愁怀萦肠，望着你离开时走的那条路，蹲下身子，久久的看着，看着，直到细雨飘摇，直到天幕落下，直到无声的哽咽。 不知道这世上，还有多少人，能与你和我一般，初遇时便禁不住心动，仿佛认识了很久，我们是那么的相似，连说话的语气，处事的方式也是这么的相像，好像是遇见了另一个自己，明明还是那么陌生，却熟悉的像是老朋友。 越相似，越了解，也越明白对方，似乎能将彼此看透，知道你的心中带着的伤，想要走近，想要安抚，想要带着清风明月，为你黯然的生活，带去新的面貌。 你也知道我怀揣着的远方和过往，和未来的路将会走向何方，却只愿面对现在，绝口不提以后，也似乎还沉浸在，那些本该尘封的旧年月里。 明晰了彼此内心深处的所想，懂得了各自的固执和坚持，即便有些话不说出口，也知道分开的时候到了。我们之间是这样的了解，连告别也不再需要，只需要默契的不再联系，不再约定晨昏之时相伴，不再述说这一天，这许多天发生过什么事，看过什么值得一笑的话。 如果还有什么迷惑的话，那便是我不知道，我们之间算是什么，是爱，是吸引，或者只是有缘相伴一程，想了很久，也想不出这究竟是怎样的一种情感，姑且称它为情。 一日又一日过去，拉开了当初的距离，从熟悉到更熟悉，从更熟悉再到陌生，原来忘却只需要不再提起，人海之中的似曾相识，是一切开始的源头。似曾相识的源头，是有着相同的过去，有着同样不能忘怀的人，执拗的不肯放下，我们之间一步之遥的距离，便成了天涯海角的隔阂。 我们这样的一段情，只能止于唇齿，你这样的一个人，只能掩于岁月。不知道在失去的时候，那是一种什么样的感觉，有些酸涩，有些不甘，有些遗憾，却又深知，这一切是必然。遇见后相互牵引，是必然，相互深深的懂得，是必然，懂得之后放手，也是必然。 曾为这样的一个人，写过这样的一首《尘心》：情人滴泪夜娑婆，万花盛放饰人间，一树一叶尽尘缘，满目空待山河远。从相遇到相离，万花盛放到秋叶凋零，所有的期待成空，所有的向往变成了尘缘里的妄想。 于是慢慢的忘却，没有错，是忘却，将他丢在风里，斩断了情丝，重新过回一个人的日子。因为找到一个彼此懂得的人，是曾经最为的期待的爱情，遇到了这样的人，却只能分离，便需要忘记，让爱消失在记忆消失前。 止于唇齿，掩于岁月。 "}}